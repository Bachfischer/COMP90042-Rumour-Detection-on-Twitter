{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "olympic-capture",
   "metadata": {},
   "source": [
    "# Rumour Analysis with Covid Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hindu-provision",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hired-burke",
   "metadata": {},
   "outputs": [],
   "source": [
    "import load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efficient-infection",
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_df = load_data.load_data(data_file = '../data/covid.data.jsonl', label_file = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intelligent-republic",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis\n",
    "\n",
    "Similiar to https://www.kaggle.com/gunesevitan/nlp-with-disaster-tweets-eda-cleaning-and-bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "available-numbers",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "thrown-authority",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_for_analysis(data_file, label_file):\n",
    "    \n",
    "    if label_file != None:\n",
    "        y_true = json.load(open(label_file))\n",
    "    \n",
    "    with open(data_file, 'r') as data_train:\n",
    "        raw_list = list(data_train)\n",
    "\n",
    "    data_list = []\n",
    "\n",
    "\n",
    "    for event in raw_list:\n",
    "        tweets_in_event = json.loads(event)\n",
    "\n",
    "        tweet = {}\n",
    "        tweet['id'] = tweets_in_event[0]['id']\n",
    "        tweet['text'] =  tweets_in_event[0]['text']\n",
    "\n",
    "        if label_file != None:\n",
    "            tweet['label'] = convert_label(y_true[str(tweet['id'])])\n",
    "        \n",
    "        data_list.append(tweet)\n",
    "\n",
    "    df = pd.DataFrame(data_list)\n",
    "\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lesser-needle",
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_df = load_data.load_data(data_file = '../data/covid.data.jsonl', label_file = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recorded-sunrise",
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spatial-trinidad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_count\n",
    "covid_df['word_count'] = covid_df['text'].apply(lambda x: len(str(x).split()))\n",
    "\n",
    "# unique_word_count\n",
    "covid_df['unique_word_count'] = covid_df['text'].apply(lambda x: len(set(str(x).split())))\n",
    "\n",
    "# stop_word_count\n",
    "covid_df['stop_word_count'] = covid_df['text'].apply(lambda x: len([w for w in str(x).lower().split() if w in STOPWORDS]))\n",
    "\n",
    "# url_count\n",
    "covid_df['url_count'] = covid_df['text'].apply(lambda x: len([w for w in str(x).lower().split() if 'http' in w or 'https' in w]))\n",
    "\n",
    "# mean_word_length\n",
    "covid_df['mean_word_length'] = covid_df['text'].apply(lambda x: np.mean([len(w) for w in str(x).split()]))\n",
    "\n",
    "# char_count\n",
    "covid_df['char_count'] = covid_df['text'].apply(lambda x: len(str(x)))\n",
    "\n",
    "# punctuation_count\n",
    "covid_df['punctuation_count'] = covid_df['text'].apply(lambda x: len([c for c in str(x) if c in string.punctuation]))\n",
    "\n",
    "# hashtag_count\n",
    "covid_df['hashtag_count'] = covid_df['text'].apply(lambda x: len([c for c in str(x) if c == '#']))\n",
    "\n",
    "# mention_count\n",
    "covid_df['mention_count'] = covid_df['text'].apply(lambda x: len([c for c in str(x) if c == '@']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minor-easter",
   "metadata": {},
   "outputs": [],
   "source": [
    "METAFEATURES = ['word_count', 'unique_word_count', 'stop_word_count', 'url_count', 'mean_word_length',\n",
    "                'char_count', 'punctuation_count', 'hashtag_count', 'mention_count']\n",
    "DISASTER_TWEETS = df_train['target'] == 1\n",
    "\n",
    "fig, axes = plt.subplots(ncols=2, nrows=len(METAFEATURES), figsize=(20, 50), dpi=100)\n",
    "\n",
    "for i, feature in enumerate(METAFEATURES):\n",
    "    sns.distplot(df_train.loc[~DISASTER_TWEETS][feature], label='Not Disaster', ax=axes[i][0], color='green')\n",
    "    sns.distplot(df_train.loc[DISASTER_TWEETS][feature], label='Disaster', ax=axes[i][0], color='red')\n",
    "\n",
    "    sns.distplot(df_train[feature], label='Training', ax=axes[i][1])\n",
    "    sns.distplot(df_test[feature], label='Test', ax=axes[i][1])\n",
    "    \n",
    "    for j in range(2):\n",
    "        axes[i][j].set_xlabel('')\n",
    "        axes[i][j].tick_params(axis='x', labelsize=12)\n",
    "        axes[i][j].tick_params(axis='y', labelsize=12)\n",
    "        axes[i][j].legend()\n",
    "    \n",
    "    axes[i][0].set_title(f'{feature} Target Distribution in Training Set', fontsize=13)\n",
    "    axes[i][1].set_title(f'{feature} Training & Test Set Distribution', fontsize=13)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "headed-arkansas",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "planned-welding",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hearing-vermont",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surface-asthma",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-3.m65",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-3:m65"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
