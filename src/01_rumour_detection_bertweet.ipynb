{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "average-fields",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stylish-obligation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import time\n",
    "import datetime\n",
    "import torch\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.nn import functional as F\n",
    "from sklearn.metrics import (f1_score, recall_score, accuracy_score,\n",
    "                                precision_score)\n",
    "from transformers import (get_linear_schedule_with_warmup,AdamW,AutoModel, AutoTokenizer,\n",
    "                            AutoModelForSequenceClassification)\n",
    "from torch.utils.data import (TensorDataset,DataLoader,\n",
    "                             RandomSampler, SequentialSampler, Dataset)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "global-gasoline",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
    "\n",
    "def format_time(elapsed):\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fourth-subscriber",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "For BERTweet we will only load the data and do not perform any preprocessing at all (even links + usernames will not be removed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "right-slovenia",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_label(label):\n",
    "    if label == \"rumour\":\n",
    "        return 1\n",
    "    elif label == \"non-rumour\":\n",
    "        return 0\n",
    "    else:\n",
    "        raise Exception(\"label classes must be 'rumour' or 'non-rumour'\")\n",
    "        \n",
    "        \n",
    "def convert_prediction(pred):\n",
    "    if pred == 1:\n",
    "        return \"rumour\"\n",
    "    elif pred == 0:\n",
    "        return \"non-rumour\"\n",
    "    else:\n",
    "        raise Exception(\"prediction classes must be '0' or '1'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "happy-screen",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_file, label_file):\n",
    "    \n",
    "    if label_file != None:\n",
    "        y_true = json.load(open(label_file))\n",
    "    \n",
    "    with open(data_file, 'r') as data_train:\n",
    "        raw_list = list(data_train)\n",
    "\n",
    "    data_list = []\n",
    "\n",
    "\n",
    "    for event in raw_list:\n",
    "        tweets_in_event = json.loads(event)\n",
    "\n",
    "        tweet = {}\n",
    "\n",
    "        tweet['id'] = tweets_in_event[0]['id']\n",
    "        tweet['text'] = tweets_in_event[0]['text']\n",
    "        \n",
    "\n",
    "        # append text from follow-up tweets in tweet chain\n",
    "        follow_up_tweets = \"\"\n",
    "        for i in range(1, len(tweets_in_event)):\n",
    "            follow_up_tweets = follow_up_tweets + tweets_in_event[i]['text'] + \" \"\n",
    "        \n",
    "        # Concatenate text from all tweets in field 'text'\n",
    "        tweet['text'] = tweet['text'] + \" \" + follow_up_tweets\n",
    "\n",
    "        \n",
    "        tweet['text'] = tweet['text'].strip()\n",
    "        if label_file != None:\n",
    "            tweet['label'] = convert_label(y_true[str(tweet['id'])])\n",
    "        \n",
    "        data_list.append(tweet)\n",
    "\n",
    "    df = pd.DataFrame(data_list)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "banner-transfer",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = load_data(data_file = '../data/train.data.jsonl', label_file = '../data/train.label.json')\n",
    "dev_df = load_data(data_file = '../data/dev.data.jsonl', label_file = '../data/dev.label.json')\n",
    "test_df = load_data(data_file = '../data/test.data.jsonl', label_file = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "standing-integrity",
   "metadata": {},
   "source": [
    "## BERTweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enclosed-copper",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_encode(df, tokenizer):\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "    for sent in df[[\"text\"]].values:\n",
    "        sent = sent.item()\n",
    "        encoded_dict = tokenizer.encode_plus(\n",
    "                            sent,                      \n",
    "                            add_special_tokens = True, \n",
    "                            max_length = 128,           \n",
    "                            pad_to_max_length = True,\n",
    "                            truncation = True,\n",
    "                            return_attention_mask = True,   \n",
    "                            return_tensors = 'pt',    \n",
    "                    )\n",
    "           \n",
    "        input_ids.append(encoded_dict['input_ids'])\n",
    "        attention_masks.append(encoded_dict['attention_mask'])\n",
    "    input_ids = torch.cat(input_ids, dim=0)\n",
    "    attention_masks = torch.cat(attention_masks, dim=0)\n",
    "\n",
    "    inputs = {\n",
    "    'input_word_ids': input_ids,\n",
    "    'input_mask': attention_masks}\n",
    "\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complete-judges",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataloaders(train_df,test_df,dev_df,batch_size=8):\n",
    "    # Load the AutoTokenizer with a normalization mode if the input Tweet is raw\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"vinai/bertweet-base\", use_fast=False, normalization=True)\n",
    "\n",
    "    tweet_valid = bert_encode(dev_df, tokenizer)\n",
    "    tweet_valid_labels = dev_df.label.astype(int)\n",
    "    \n",
    "    tweet_train = bert_encode(train_df, tokenizer)\n",
    "    tweet_train_labels = train_df.label.astype(int)\n",
    "    \n",
    "    tweet_test = bert_encode(test_df, tokenizer)\n",
    "\n",
    "\n",
    "    input_ids, attention_masks = tweet_train.values()\n",
    "    labels = torch.tensor(tweet_train_labels.values)\n",
    "    train_dataset = TensorDataset(input_ids, attention_masks, labels)\n",
    "    \n",
    "    input_ids, attention_masks = tweet_valid.values()\n",
    "    labels = torch.tensor(tweet_valid_labels.values)\n",
    "    val_dataset = TensorDataset(input_ids, attention_masks, labels)\n",
    "    \n",
    "    input_ids, attention_masks = tweet_test.values()\n",
    "    test_dataset = TensorDataset(input_ids, attention_masks)\n",
    "\n",
    "    \n",
    "    train_dataloader = DataLoader(\n",
    "                train_dataset,\n",
    "                sampler = RandomSampler(train_dataset), \n",
    "                batch_size = batch_size \n",
    "            )\n",
    "\n",
    "\n",
    "    validation_dataloader = DataLoader(\n",
    "                val_dataset, \n",
    "                sampler = SequentialSampler(val_dataset),\n",
    "                batch_size = batch_size \n",
    "            )\n",
    "\n",
    "\n",
    "    test_dataloader = DataLoader(\n",
    "                test_dataset, \n",
    "                sampler = SequentialSampler(test_dataset), \n",
    "                batch_size = batch_size\n",
    "            )\n",
    "    return train_dataloader,validation_dataloader,test_dataloader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cardiac-ordering",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader,validation_dataloader,test_dataloader = prepare_dataloaders(train_df, test_df, dev_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "neural-walter",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atmospheric-operations",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_encode(sentence):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"vinai/bertweet-base\", use_fast=False, normalization=True)\n",
    "\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        sentence,                      \n",
    "                        add_special_tokens = True, \n",
    "                        max_length = 128,           \n",
    "                        pad_to_max_length = True,\n",
    "                        truncation = True,\n",
    "                        return_attention_mask = True,   \n",
    "                        return_tensors = 'pt',    \n",
    "                )\n",
    "           \n",
    "    return encoded_dict['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "gorgeous-latex",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_decode(tokens):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"vinai/bertweet-base\", use_fast=False, normalization=True)\n",
    "    return tokenizer.convert_ids_to_tokens(tokens)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polar-office",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "settled-single",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_test = train_df.text[0]\n",
    "text_preprocessed = test_encode(text_test)\n",
    "\n",
    "\n",
    "print(f'Shape      : {text_preprocessed.shape}')\n",
    "print(f'Word Ids   : {text_preprocessed[0, :128]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hungry-nitrogen",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_test = train_df.text[0]\n",
    "text_preprocessed = test_encode(text_test)\n",
    "\n",
    "\n",
    "print(f'Shape      : {text_preprocessed.shape}')\n",
    "print(f'Word Ids   : {text_preprocessed[0, :128]}')\n",
    "print(test_decode(text_preprocessed[0, :128]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bridal-reconstruction",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "narrative-literature",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_model(model_class=\"vinai/bertweet-base\",num_classes=2,model_to_load=None,total_steps=-1):\n",
    "\n",
    "\n",
    "\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        model_class,\n",
    "        num_labels = num_classes,  \n",
    "        output_attentions = False, \n",
    "        output_hidden_states = False,\n",
    "    )\n",
    "\n",
    "    optimizer = AdamW(model.parameters(),\n",
    "                    lr = 5e-5,\n",
    "                    eps = 1e-8\n",
    "                    )\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                                num_warmup_steps = 0, \n",
    "                                                num_training_steps = total_steps)\n",
    "\n",
    "    if model_to_load is not None:\n",
    "        try:\n",
    "            model.roberta.load_state_dict(torch.load(model_to_load))\n",
    "            print(\"LOADED MODEL\")\n",
    "        except:\n",
    "            pass\n",
    "    return model, optimizer, scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enabling-debate",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "model, optimizer, scheduler = prepare_model(\"vinai/bertweet-base\" ,num_classes=2, model_to_load=None, total_steps = total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smaller-writer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model,test_dataloader):\n",
    "    model.eval()\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    model.to(device)\n",
    "    preds = []\n",
    "    total_eval_accuracy = 0\n",
    "    total_eval_loss = 0\n",
    "    nb_eval_steps = 0\n",
    "    t0 = time.time()\n",
    "    for batch in test_dataloader:\n",
    "        \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "        with torch.no_grad():        \n",
    "            outputs = model(b_input_ids, \n",
    "                                   token_type_ids=None, \n",
    "                                   attention_mask=b_input_mask,\n",
    "                                   labels=b_labels)\n",
    "            loss = outputs.loss\n",
    "            logits = outputs.logits\n",
    "\n",
    "        total_eval_loss += loss.item()\n",
    "\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "        preds.append(logits)\n",
    "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
    "        \n",
    "\n",
    "    avg_val_accuracy = total_eval_accuracy / len(test_dataloader)\n",
    "    print(\"  Accuracy: {0:.2f} %\".format(avg_val_accuracy*100))\n",
    "    avg_val_loss = total_eval_loss / len(test_dataloader)\n",
    "    validation_time = format_time(time.time() - t0)\n",
    "    print(\"  Test Loss: {0:.2f}\".format(avg_val_loss))\n",
    "    print(\"  Test took: {:}\".format(validation_time))\n",
    "    return preds, avg_val_accuracy, avg_val_loss, validation_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comfortable-august",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,optimizer,scheduler,train_dataloader,validation_dataloader,epochs):\n",
    "    seed_val = 42\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    model.to(device)\n",
    "    random.seed(seed_val)\n",
    "    np.random.seed(seed_val)\n",
    "    torch.manual_seed(seed_val)\n",
    "    torch.cuda.manual_seed_all(seed_val)\n",
    "    training_stats = []\n",
    "    total_t0 = time.time()\n",
    "\n",
    "    for epoch_i in range(0, epochs):\n",
    "\n",
    "        print(\"\")\n",
    "        print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "        print('Training...')\n",
    "        \n",
    "        t0 = time.time()\n",
    "        total_train_loss = 0\n",
    "        model.train()\n",
    "        for step, batch in enumerate(train_dataloader):\n",
    "            if step % 40 == 0 and not step == 0:\n",
    "                elapsed = format_time(time.time() - t0)\n",
    "                print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "            b_input_ids = batch[0].to(device)\n",
    "            b_input_mask = batch[1].to(device)\n",
    "            b_labels = batch[2].to(device)\n",
    "            model.zero_grad()        \n",
    "            outputs = model(b_input_ids, \n",
    "                                token_type_ids=None, \n",
    "                                attention_mask=b_input_mask, \n",
    "                                labels=b_labels)\n",
    "            loss = outputs.loss\n",
    "            logits = outputs.logits\n",
    "            total_train_loss += loss.item()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "        avg_train_loss = total_train_loss / len(train_dataloader)            \n",
    "        training_time = format_time(time.time() - t0)\n",
    "\n",
    "        print(\"\")\n",
    "        print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "        print(\"  Training epcoh took: {:}\".format(training_time))\n",
    "            \n",
    "        _, avg_val_accuracy, avg_val_loss, validation_time = validate(model,validation_dataloader)\n",
    "        training_stats.append(\n",
    "            {\n",
    "                'epoch': epoch_i + 1,\n",
    "                'Training Loss': avg_train_loss,\n",
    "                'Valid. Loss': avg_val_loss,\n",
    "                'Valid. Accur.': avg_val_accuracy,\n",
    "                'Training Time': training_time,\n",
    "                'Validation Time': validation_time\n",
    "            }\n",
    "        )\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Training complete!\")\n",
    "\n",
    "    print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "checked-easter",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(model,optimizer,scheduler,train_dataloader,validation_dataloader, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appointed-citation",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.cpu().roberta.state_dict(),\"./bertweet/bertweet_v21\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "revolutionary-airport",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atomic-realtor",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model,test_dataloader):\n",
    "    model.eval()\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    model.to(device)\n",
    "    preds = []\n",
    "\n",
    "    for batch in test_dataloader:\n",
    "        \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        with torch.no_grad():        \n",
    "            outputs = model(b_input_ids, \n",
    "                                   token_type_ids=None, \n",
    "                                   attention_mask=b_input_mask)\n",
    "            logits = outputs.logits\n",
    "\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        for logit in logits:\n",
    "            preds.append(logit)\n",
    "\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interesting-debate",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = predict(model,test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becoming-operation",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import softmax\n",
    "\n",
    "pred_labels = np.argmax(result, axis = 1)\n",
    "\n",
    "pred_scores = softmax(result, axis=1)[:, 1]\n",
    "\n",
    "predicted_labels = [convert_prediction(pred) for pred in pred_labels]\n",
    "\n",
    "output = pd.DataFrame({'id':test_df.id,'target':predicted_labels})\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "colored-price",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.Series(output.target.values,index=output.id).to_dict()\n",
    "with open('test-output.json', 'w') as f:\n",
    "    json.dump(submission, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "serial-lemon",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "minimal-focus",
   "metadata": {},
   "source": [
    "## BERTweet with merged dataset (i.e. train + dev data has been merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "educational-childhood",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = train_df.append(dev_df, ignore_index = True)\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "other-vault",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "perfect-softball",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataloaders(combined_df,test_df,tokenizer_class=\"vinai/bertweet-base\",batch_size=8):\n",
    "    # Load the AutoTokenizer with a normalization mode if the input Tweet is raw\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained(tokenizer_class, use_fast=False, normalization=True)\n",
    "\n",
    "    \n",
    "    tweet_train = bert_encode(combined_df, tokenizer)\n",
    "    tweet_train_labels = combined_df.label.astype(int)\n",
    "    \n",
    "    tweet_test = bert_encode(test_df, tokenizer)\n",
    "\n",
    "\n",
    "    input_ids, attention_masks = tweet_train.values()\n",
    "    labels = torch.tensor(tweet_train_labels.values)\n",
    "    train_dataset = TensorDataset(input_ids, attention_masks, labels)\n",
    "    \n",
    "    input_ids, attention_masks = tweet_test.values()\n",
    "    test_dataset = TensorDataset(input_ids, attention_masks)\n",
    "\n",
    "    \n",
    "    train_dataloader = DataLoader(\n",
    "                train_dataset,\n",
    "                sampler = RandomSampler(train_dataset), \n",
    "                batch_size = batch_size \n",
    "            )\n",
    "\n",
    "    test_dataloader = DataLoader(\n",
    "                test_dataset, \n",
    "                sampler = SequentialSampler(test_dataset), \n",
    "                batch_size = batch_size\n",
    "            )\n",
    "    return train_dataloader,test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entitled-offset",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader,test_dataloader = prepare_dataloaders(combined_df, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "technological-encyclopedia",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_model(model_class=\"vinai/bertweet-base\",num_classes=2,model_to_load=None,total_steps=-1):\n",
    "\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        model_class,\n",
    "        num_labels = num_classes,  \n",
    "        output_attentions = False, \n",
    "        output_hidden_states = False,\n",
    "    )\n",
    "\n",
    "    optimizer = AdamW(model.parameters(),\n",
    "                    lr = 5e-5,\n",
    "                    eps = 1e-8\n",
    "                    )\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                                num_warmup_steps = 0, \n",
    "                                                num_training_steps = total_steps)\n",
    "\n",
    "    if model_to_load is not None:\n",
    "        try:\n",
    "            model.roberta.load_state_dict(torch.load(model_to_load))\n",
    "            print(\"LOADED MODEL\")\n",
    "        except:\n",
    "            pass\n",
    "    return model, optimizer, scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pending-queensland",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "model, optimizer, scheduler = prepare_model(\"vinai/bertweet-base\" ,num_classes=2, model_to_load=None, total_steps = total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reported-booking",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,optimizer,scheduler,train_dataloader,epochs):\n",
    "    seed_val = 42\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    model.to(device)\n",
    "    random.seed(seed_val)\n",
    "    np.random.seed(seed_val)\n",
    "    torch.manual_seed(seed_val)\n",
    "    torch.cuda.manual_seed_all(seed_val)\n",
    "    training_stats = []\n",
    "    total_t0 = time.time()\n",
    "\n",
    "    for epoch_i in range(0, epochs):\n",
    "\n",
    "        print(\"\")\n",
    "        print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "        print('Training...')\n",
    "        \n",
    "        t0 = time.time()\n",
    "        total_train_loss = 0\n",
    "        model.train()\n",
    "        for step, batch in enumerate(train_dataloader):\n",
    "            if step % 40 == 0 and not step == 0:\n",
    "                elapsed = format_time(time.time() - t0)\n",
    "                print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "            b_input_ids = batch[0].to(device)\n",
    "            b_input_mask = batch[1].to(device)\n",
    "            b_labels = batch[2].to(device)\n",
    "            model.zero_grad()        \n",
    "            outputs = model(b_input_ids, \n",
    "                                token_type_ids=None, \n",
    "                                attention_mask=b_input_mask, \n",
    "                                labels=b_labels)\n",
    "            loss = outputs.loss\n",
    "            logits = outputs.logits\n",
    "            total_train_loss += loss.item()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "        avg_train_loss = total_train_loss / len(train_dataloader)            \n",
    "        training_time = format_time(time.time() - t0)\n",
    "\n",
    "        print(\"\")\n",
    "        print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "        print(\"  Training epcoh took: {:}\".format(training_time))\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Training complete!\")\n",
    "\n",
    "    print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "straight-horizon",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(model,optimizer,scheduler,train_dataloader, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "royal-separation",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.cpu().roberta.state_dict(),\"./bertweet/bertweet_v28\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sustainable-custody",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "essential-cleaning",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model,test_dataloader):\n",
    "    model.eval()\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    model.to(device)\n",
    "    preds = []\n",
    "\n",
    "    for batch in test_dataloader:\n",
    "        \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        with torch.no_grad():        \n",
    "            outputs = model(b_input_ids, \n",
    "                                   token_type_ids=None, \n",
    "                                   attention_mask=b_input_mask)\n",
    "            logits = outputs.logits\n",
    "\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        for logit in logits:\n",
    "            preds.append(logit)\n",
    "\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "further-warehouse",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = predict(model,test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "million-monaco",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import softmax\n",
    "\n",
    "pred_labels = np.argmax(result, axis = 1)\n",
    "\n",
    "pred_scores = softmax(result, axis=1)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "authorized-african",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = [convert_prediction(pred) for pred in pred_labels]\n",
    "\n",
    "output = pd.DataFrame({'id':test_df.id,'target':predicted_labels})\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alert-tract",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.Series(output.target.values,index=output.id).to_dict()\n",
    "with open('test-output_v27.json', 'w') as f:\n",
    "    json.dump(submission, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smooth-gambling",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "running-marketing",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorrect-bacon",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
