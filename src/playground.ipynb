{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "future-tension",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# TODO: Check whether spacy is allowed\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abroad-degree",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Load latest multimodal_transformers from GitHub to allow dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adjusted-gnome",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "from typing import Optional\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoConfig,\n",
    "    Trainer,\n",
    "    EvalPrediction,\n",
    "    set_seed\n",
    ")\n",
    "from transformers.training_args import TrainingArguments\n",
    "\n",
    "from multimodal_transformers.data import load_data_from_folder\n",
    "from multimodal_transformers.model import TabularConfig\n",
    "from multimodal_transformers.model import AutoModelWithTabular\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "os.environ['COMET_MODE'] = 'DISABLED'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "advanced-morgan",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_label(label):\n",
    "    if label == \"rumour\":\n",
    "        return 1\n",
    "    elif label == \"non-rumour\":\n",
    "        return 0\n",
    "    else:\n",
    "        raise Exception(\"label classes must be 'rumour' or 'non-rumour'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "analyzed-public",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_prediction(pred):\n",
    "    if pred == 1:\n",
    "        return \"rumour\"\n",
    "    elif pred == 0:\n",
    "        return \"non-rumour\"\n",
    "    else:\n",
    "        raise Exception(\"prediction classes must be '0' or '1'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "romantic-brooklyn",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(tweet):\n",
    "    tweet_features = {}\n",
    "    \n",
    "    ### Tweet features\n",
    "    tweet_features['text'] = tweet['text']\n",
    "    \n",
    "    # Number of retweets\n",
    "    tweet_features['retweet_count'] = tweet['retweet_count']\n",
    "    #Number of favorites\n",
    "    tweet_features['favorite_count'] = tweet['favorite_count']\n",
    "    \n",
    "    #Whether tweet has a question mark\n",
    "    tweet_features['question_mark'] = '?' in tweet['text']\n",
    "    \n",
    "    #Whether tweet contains URLs\n",
    "    if 'urls' in tweet['entities']:\n",
    "        number_of_urls = len(tweet['entities']['urls'])\n",
    "    else: \n",
    "        number_of_urls = 0\n",
    "        \n",
    "    tweet_features['contains_url'] = True if number_of_urls > 0 else False\n",
    "    \n",
    "    #Number of URLs embedded in tweet\n",
    "    tweet_features['number_urls'] =  number_of_urls\n",
    "    \n",
    "    #Whether tweet has native media\n",
    "    if 'media' in tweet['entities']:\n",
    "        number_of_media = len(tweet['entities']['media'])\n",
    "    else: \n",
    "        number_of_media = 0\n",
    "        \n",
    "    tweet_features['contains_media'] = True if number_of_media > 0 else False\n",
    "    \n",
    "    \n",
    "    ### User features\n",
    "    user_features = {}\n",
    "    \n",
    "    # Number of posts user has posted\n",
    "    user_features['statuses_count'] = tweet['user']['statuses_count']\n",
    "    \n",
    "    #Number of public lists user belongs to\n",
    "    user_features['listed_count'] = tweet['user']['listed_count']\n",
    "\n",
    "\n",
    "    #Number of followers\n",
    "    user_features['followers_count'] = tweet['user']['followers_count']\n",
    "\n",
    "    #Number of followings\n",
    "    user_features['friends_count'] = tweet['user']['friends_count']\n",
    "\n",
    "    #Whether user has a background profile image\n",
    "    if 'profile_background_image_url' in tweet['user']:\n",
    "        profile_background_image_url = True\n",
    "    else:\n",
    "        profile_background_image_url = False\n",
    "    \n",
    "    user_features['contains_profile_background_image'] = profile_background_image_url\n",
    "    \n",
    "    #User reputation (i.e., followers/(followings+1))\n",
    "    user_features['reputation_score_1'] = user_features['followers_count'] / ( user_features['friends_count'] +1)\n",
    "    \n",
    "    #User reputation (i.e., followers/(followings+followers+1))\n",
    "    user_features['reputation_score_2'] = user_features['followers_count'] /(user_features['followers_count'] +\n",
    "                                                                              user_features['friends_count'] +1)\n",
    "\n",
    "    # Number of tweets user has liked so far (aka ”user favorites”)\n",
    "    user_features['favourites_count'] = tweet['user']['favourites_count']\n",
    "\n",
    "    # Account age in days\n",
    "    # TODO\n",
    "    \n",
    "    # Following rate (i.e., followings / (account age+1))\n",
    "    # TODO\n",
    "    \n",
    "    # Favorite rate (i.e., user favorites / (account age+1))\n",
    "    # TODO\n",
    "    \n",
    "    # User engagement (i.e., # posts / (account age+1))\n",
    "    # TODO\n",
    "    \n",
    "    # Response time decay (time difference between context and source tweet in mins)\n",
    "    # TODO\n",
    "    \n",
    "    # Whether user is verified\n",
    "    user_features['verified'] = tweet['user']['verified']\n",
    "\n",
    "    # Whether geolocation is enabled\n",
    "    user_features['geo_enabled'] = tweet['user']['geo_enabled']\n",
    "\n",
    "    # Number of words in user description\n",
    "    if 'description' in tweet['user'] and tweet['user']['description'] != None:\n",
    "        length_description = len(tweet['user']['description'])\n",
    "    else:\n",
    "        length_description = 0\n",
    "        \n",
    "    # Whether user has a description\n",
    "    user_features['has_description'] = True if length_description > 0 else False\n",
    "        \n",
    "    user_features['length_description'] = length_description\n",
    "\n",
    "    \n",
    "    # Merge features\n",
    "    tweet_features.update(user_features)\n",
    "    return tweet_features\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "leading-twelve",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "automated-atlanta",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decontracted(phrase):\n",
    "    # specific\n",
    "    phrase = re.sub(r\"won\\'t\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
    "\n",
    "    # general\n",
    "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "    return phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "electrical-auction",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import re\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def preprocessing(text, perform_stemming):\n",
    "    text = text.replace('#','')\n",
    "    text = decontracted(text)\n",
    "    text = re.sub('\\S*@\\S*\\s?','',text)\n",
    "    if perform_stemming == True:\n",
    "        text = re.sub('http[s]?:(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+','',text)\n",
    "        text = re.sub('[^A-z]', ' ',text.lower())\n",
    "    else:\n",
    "        text = re.sub('http[s]?:(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),])+','',text)\n",
    "\n",
    "    token=[]\n",
    "    result=''\n",
    "    \n",
    "    if perform_stemming == True:\n",
    "        text = nlp(text)\n",
    "        for t in text:\n",
    "            if not t.is_stop and len(t)>2:  \n",
    "                token.append(t.lemma_)\n",
    "        result = ' '.join([i for i in token])\n",
    "    else:\n",
    "        result = text\n",
    "        \n",
    "    return result.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "previous-philippines",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_file, label_file, perform_stemming):\n",
    "    \n",
    "    if label_file != None:\n",
    "        y_true = json.load(open(label_file))\n",
    "    \n",
    "    with open(data_file, 'r') as data_train:\n",
    "        raw_list = list(data_train)\n",
    "\n",
    "    data_list = []\n",
    "\n",
    "\n",
    "    for event in raw_list:\n",
    "        tweets_in_event = json.loads(event)\n",
    "\n",
    "        tweet = {}\n",
    "\n",
    "        tweet['id'] = tweets_in_event[0]['id']\n",
    "        tweet.update(extract_features(tweets_in_event[0]))\n",
    "        \n",
    "\n",
    "        # append text from follow-up tweets in tweet chain\n",
    "        follow_up_tweets = \"\"\n",
    "        for i in range(1, len(tweets_in_event)):\n",
    "            follow_up_tweets = follow_up_tweets + preprocessing(tweets_in_event[i]['text'], perform_stemming) + \" [SEP] \"\n",
    "        \n",
    "        # Concatenate text from all tweets in field 'text'\n",
    "        tweet['text'] = preprocessing(tweet['text'], perform_stemming) + \" [SEP] \" + follow_up_tweets\n",
    "        tweet['text'] = tweet['text'].strip()\n",
    "        if label_file != None:\n",
    "            tweet['label'] = convert_label(y_true[str(tweet['id'])])\n",
    "        \n",
    "        data_list.append(tweet)\n",
    "\n",
    "    df = pd.DataFrame(data_list)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "operating-input",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = load_data(data_file = '../data/train.data.jsonl', label_file = '../data/train.label.json', perform_stemming = False)\n",
    "dev_df = load_data(data_file = '../data/dev.data.jsonl', label_file = '../data/dev.label.json', perform_stemming = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "embedded-gamma",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = load_data(data_file = '../data/test.data.jsonl', label_file = None, perform_stemming = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "elementary-latvia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.title('Train Data')\n",
    "plt.xlabel('Target Distribution')\n",
    "plt.ylabel('Samples')\n",
    "plt.hist(train_df.label)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "spiritual-penguin",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>question_mark</th>\n",
       "      <th>contains_url</th>\n",
       "      <th>number_urls</th>\n",
       "      <th>contains_media</th>\n",
       "      <th>statuses_count</th>\n",
       "      <th>listed_count</th>\n",
       "      <th>...</th>\n",
       "      <th>friends_count</th>\n",
       "      <th>contains_profile_background_image</th>\n",
       "      <th>reputation_score_1</th>\n",
       "      <th>reputation_score_2</th>\n",
       "      <th>favourites_count</th>\n",
       "      <th>verified</th>\n",
       "      <th>geo_enabled</th>\n",
       "      <th>has_description</th>\n",
       "      <th>length_description</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>552800070199148544</td>\n",
       "      <td>How to respond to the murderous attack on Char...</td>\n",
       "      <td>228</td>\n",
       "      <td>77</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>27923</td>\n",
       "      <td>185</td>\n",
       "      <td>...</td>\n",
       "      <td>414</td>\n",
       "      <td>True</td>\n",
       "      <td>9.985542</td>\n",
       "      <td>0.908971</td>\n",
       "      <td>500</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>544388259359387648</td>\n",
       "      <td>You can not condemn an entire race, nation or ...</td>\n",
       "      <td>352</td>\n",
       "      <td>252</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>745</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>222</td>\n",
       "      <td>True</td>\n",
       "      <td>0.704036</td>\n",
       "      <td>0.413158</td>\n",
       "      <td>428</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>115</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>552805970536333314</td>\n",
       "      <td>Attempts to extend blame for this to all Musli...</td>\n",
       "      <td>876</td>\n",
       "      <td>400</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>74137</td>\n",
       "      <td>1431</td>\n",
       "      <td>...</td>\n",
       "      <td>1658</td>\n",
       "      <td>True</td>\n",
       "      <td>21.040989</td>\n",
       "      <td>0.954630</td>\n",
       "      <td>6423</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>149</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>525071376084791297</td>\n",
       "      <td>Rest in Peace, Cpl. Nathan Cirillo. Killed tod...</td>\n",
       "      <td>112</td>\n",
       "      <td>96</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>28103</td>\n",
       "      <td>418</td>\n",
       "      <td>...</td>\n",
       "      <td>1052</td>\n",
       "      <td>True</td>\n",
       "      <td>14.048433</td>\n",
       "      <td>0.933548</td>\n",
       "      <td>2140</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>157</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>498355319979143168</td>\n",
       "      <td>People DEBATING whether MikeBrown shoplifted o...</td>\n",
       "      <td>802</td>\n",
       "      <td>298</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>55920</td>\n",
       "      <td>65</td>\n",
       "      <td>...</td>\n",
       "      <td>914</td>\n",
       "      <td>True</td>\n",
       "      <td>2.114754</td>\n",
       "      <td>0.678947</td>\n",
       "      <td>25389</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>156</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5216</th>\n",
       "      <td>525025279803424768</td>\n",
       "      <td>The soldier shot dead in Wednesday is Ottawa a...</td>\n",
       "      <td>119</td>\n",
       "      <td>36</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>88483</td>\n",
       "      <td>306</td>\n",
       "      <td>...</td>\n",
       "      <td>2454</td>\n",
       "      <td>True</td>\n",
       "      <td>2.663951</td>\n",
       "      <td>0.727071</td>\n",
       "      <td>1903</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>101</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5217</th>\n",
       "      <td>552784600502915072</td>\n",
       "      <td>Charlie Hebdo became well known for publishing...</td>\n",
       "      <td>202</td>\n",
       "      <td>41</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>15128</td>\n",
       "      <td>1657</td>\n",
       "      <td>...</td>\n",
       "      <td>2268</td>\n",
       "      <td>True</td>\n",
       "      <td>18.330101</td>\n",
       "      <td>0.948267</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>158</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5218</th>\n",
       "      <td>499696525808001024</td>\n",
       "      <td>We got through. That is a sniper on top of a t...</td>\n",
       "      <td>432</td>\n",
       "      <td>55</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>61902</td>\n",
       "      <td>1627</td>\n",
       "      <td>...</td>\n",
       "      <td>521</td>\n",
       "      <td>True</td>\n",
       "      <td>54.639847</td>\n",
       "      <td>0.982027</td>\n",
       "      <td>1163</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>159</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5219</th>\n",
       "      <td>580320612155060224</td>\n",
       "      <td>Last position of Germanwings flight 4U9525 at ...</td>\n",
       "      <td>3092</td>\n",
       "      <td>480</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>7991</td>\n",
       "      <td>2384</td>\n",
       "      <td>...</td>\n",
       "      <td>369</td>\n",
       "      <td>True</td>\n",
       "      <td>578.891892</td>\n",
       "      <td>0.998276</td>\n",
       "      <td>1131</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>146</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5220</th>\n",
       "      <td>553218279557582849</td>\n",
       "      <td>Kudos to Google for donating €250,000 to help ...</td>\n",
       "      <td>151</td>\n",
       "      <td>100</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>133992</td>\n",
       "      <td>4642</td>\n",
       "      <td>...</td>\n",
       "      <td>3524</td>\n",
       "      <td>True</td>\n",
       "      <td>17.401135</td>\n",
       "      <td>0.945656</td>\n",
       "      <td>36328</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>159</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5221 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id                                               text  \\\n",
       "0     552800070199148544  How to respond to the murderous attack on Char...   \n",
       "1     544388259359387648  You can not condemn an entire race, nation or ...   \n",
       "2     552805970536333314  Attempts to extend blame for this to all Musli...   \n",
       "3     525071376084791297  Rest in Peace, Cpl. Nathan Cirillo. Killed tod...   \n",
       "4     498355319979143168  People DEBATING whether MikeBrown shoplifted o...   \n",
       "...                  ...                                                ...   \n",
       "5216  525025279803424768  The soldier shot dead in Wednesday is Ottawa a...   \n",
       "5217  552784600502915072  Charlie Hebdo became well known for publishing...   \n",
       "5218  499696525808001024  We got through. That is a sniper on top of a t...   \n",
       "5219  580320612155060224  Last position of Germanwings flight 4U9525 at ...   \n",
       "5220  553218279557582849  Kudos to Google for donating €250,000 to help ...   \n",
       "\n",
       "      retweet_count  favorite_count  question_mark  contains_url  number_urls  \\\n",
       "0               228              77           True         False            0   \n",
       "1               352             252          False         False            0   \n",
       "2               876             400          False         False            0   \n",
       "3               112              96          False          True            1   \n",
       "4               802             298          False         False            0   \n",
       "...             ...             ...            ...           ...          ...   \n",
       "5216            119              36          False         False            0   \n",
       "5217            202              41          False         False            0   \n",
       "5218            432              55          False          True            1   \n",
       "5219           3092             480          False          True            1   \n",
       "5220            151             100          False          True            1   \n",
       "\n",
       "      contains_media  statuses_count  listed_count  ...  friends_count  \\\n",
       "0               True           27923           185  ...            414   \n",
       "1              False             745             2  ...            222   \n",
       "2              False           74137          1431  ...           1658   \n",
       "3               True           28103           418  ...           1052   \n",
       "4              False           55920            65  ...            914   \n",
       "...              ...             ...           ...  ...            ...   \n",
       "5216            True           88483           306  ...           2454   \n",
       "5217           False           15128          1657  ...           2268   \n",
       "5218           False           61902          1627  ...            521   \n",
       "5219            True            7991          2384  ...            369   \n",
       "5220           False          133992          4642  ...           3524   \n",
       "\n",
       "      contains_profile_background_image  reputation_score_1  \\\n",
       "0                                  True            9.985542   \n",
       "1                                  True            0.704036   \n",
       "2                                  True           21.040989   \n",
       "3                                  True           14.048433   \n",
       "4                                  True            2.114754   \n",
       "...                                 ...                 ...   \n",
       "5216                               True            2.663951   \n",
       "5217                               True           18.330101   \n",
       "5218                               True           54.639847   \n",
       "5219                               True          578.891892   \n",
       "5220                               True           17.401135   \n",
       "\n",
       "      reputation_score_2  favourites_count  verified  geo_enabled  \\\n",
       "0               0.908971               500     False        False   \n",
       "1               0.413158               428     False        False   \n",
       "2               0.954630              6423     False         True   \n",
       "3               0.933548              2140      True         True   \n",
       "4               0.678947             25389     False        False   \n",
       "...                  ...               ...       ...          ...   \n",
       "5216            0.727071              1903      True         True   \n",
       "5217            0.948267                 0      True         True   \n",
       "5218            0.982027              1163     False         True   \n",
       "5219            0.998276              1131      True         True   \n",
       "5220            0.945656             36328      True         True   \n",
       "\n",
       "      has_description  length_description  label  \n",
       "0                True                  46      0  \n",
       "1                True                 115      0  \n",
       "2                True                 149      0  \n",
       "3                True                 157      1  \n",
       "4                True                 156      0  \n",
       "...               ...                 ...    ...  \n",
       "5216             True                 101      1  \n",
       "5217             True                 158      0  \n",
       "5218             True                 159      0  \n",
       "5219             True                 146      1  \n",
       "5220             True                 159      0  \n",
       "\n",
       "[5221 rows x 21 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df = train_df.append(dev_df, ignore_index = True)\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "external-frank",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "580"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dev_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "artistic-cambodia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"How to respond to the murderous attack on Charlie Hebdo? Every newspaper in the free world should print this. [SEP] Jews label anyone they do not like as Anti-Semite and campaign until that person/company is finished. [SEP] No one does. [SEP] ImCharlieHebdo [SEP] Ditto [SEP] What innocent Muslims ought to find insulting is an atrocity committed in their name, not a sodding cartoon. [SEP] Yes, until it becomes yours. [SEP] Why insult people who have nothing to do with this? People are genuinely offended by such drawings. [SEP] And neither am I! I think this has little to do with actual Muslims. [SEP] Ah, you do not like Jews. Bye bye. [SEP] Also they kid you along with benign stuff then ... WHAM it is like a river of shite! [SEP] It is a good point [SEP] How about this? [SEP] Organised Jewry, I mean, not the actual people. Otherwise I would be hating on my own ancestors. [SEP] ...and this: [SEP] explored. [SEP] And if that is the case, that is your problem. [SEP] No point insulting billions of innocent muslims just to thumb our noses at a bunch of lunatics.They are not worth it [SEP] Oh dear... Just saw those tweets... Blocked him. [SEP] Because they have to learn to not be offended, that is why. [SEP] But by that token Jews, Blacks and Irish people would have to 'learn' not to be offended either [SEP] I get that ... I defend the right to free speech however there is a much broader context to this which is not [SEP] just for the record. I am not in any way, shape or form defending this atrocity. [SEP] Yes, remind me when was the last time Jews bombed the Guardian. [SEP] I know!  Gives me the creeps. [SEP] There is a lot of very dodgy Twitter accounts who seem benign then you see the real side :( [SEP] If people insult something that is important to you, you feel that your identity is under attack. [SEP] It is remarkable how quickly they come out the woodwork. [SEP] Why is the correct response to brutality to offend lots of people who *do not* support that brutality? [SEP]\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df['text'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "auburn-nightmare",
   "metadata": {},
   "source": [
    "## Multi-modal BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "mediterranean-session",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ModelArguments:\n",
    "    \"\"\"\n",
    "    Arguments pertaining to which model/config/tokenizer we are going to fine-tune from.\n",
    "    \"\"\"\n",
    "    model_name_or_path: str = field(\n",
    "      metadata={\"help\": \"Path to pretrained model or model identifier from huggingface.co/models\"}\n",
    "    )\n",
    "    config_name: Optional[str] = field(\n",
    "      default=None, metadata={\"help\": \"Pretrained config name or path if not the same as model_name\"}\n",
    "    )\n",
    "    tokenizer_name: Optional[str] = field(\n",
    "      default=None, metadata={\"help\": \"Pretrained tokenizer name or path if not the same as model_name\"}\n",
    "    )\n",
    "    cache_dir: Optional[str] = field(\n",
    "      default=None, metadata={\"help\": \"Where do you want to store the pretrained models downloaded from s3\"}\n",
    "    )\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class MultimodalDataTrainingArguments:\n",
    "    \"\"\"\n",
    "    Arguments pertaining to how we combine tabular features\n",
    "    Using `HfArgumentParser` we can turn this class\n",
    "    into argparse arguments to be able to specify them on\n",
    "    the command line.\n",
    "    \"\"\"\n",
    "\n",
    "    data_path: str = field(metadata={\n",
    "                            'help': 'the path to the csv file containing the dataset'\n",
    "                        })\n",
    "    column_info_path: str = field(\n",
    "      default=None,\n",
    "      metadata={\n",
    "          'help': 'the path to the json file detailing which columns are text, categorical, numerical, and the label'\n",
    "    })\n",
    "\n",
    "    column_info: dict = field(\n",
    "      default=None,\n",
    "      metadata={\n",
    "          'help': 'a dict referencing the text, categorical, numerical, and label columns'\n",
    "                  'its keys are text_cols, num_cols, cat_cols, and label_col'\n",
    "    })\n",
    "\n",
    "    categorical_encode_type: str = field(default='ohe',\n",
    "                                        metadata={\n",
    "                                            'help': 'sklearn encoder to use for categorical data',\n",
    "                                            'choices': ['ohe', 'binary', 'label', 'none']\n",
    "                                        })\n",
    "    numerical_transformer_method: str = field(default='yeo_johnson',\n",
    "                                            metadata={\n",
    "                                                'help': 'sklearn numerical transformer to preprocess numerical data',\n",
    "                                                'choices': ['yeo_johnson', 'box_cox', 'quantile_normal', 'none']\n",
    "                                            })\n",
    "    task: str = field(default=\"classification\",\n",
    "                    metadata={\n",
    "                        \"help\": \"The downstream training task\",\n",
    "                        \"choices\": [\"classification\", \"regression\"]\n",
    "                    })\n",
    "\n",
    "    mlp_division: int = field(default=4,\n",
    "                            metadata={\n",
    "                                'help': 'the ratio of the number of '\n",
    "                                        'hidden dims in a current layer to the next MLP layer'\n",
    "                            })\n",
    "    combine_feat_method: str = field(default='individual_mlps_on_cat_and_numerical_feats_then_concat',\n",
    "                                    metadata={\n",
    "                                        'help': 'method to combine categorical and numerical features, '\n",
    "                                                'see README for all the method'\n",
    "                                    })\n",
    "    mlp_dropout: float = field(default=0.1,\n",
    "                              metadata={\n",
    "                                'help': 'dropout ratio used for MLP layers'\n",
    "                              })\n",
    "    numerical_bn: bool = field(default=True,\n",
    "                              metadata={\n",
    "                                  'help': 'whether to use batchnorm on numerical features'\n",
    "                              })\n",
    "    use_simple_classifier: str = field(default=True,\n",
    "                                      metadata={\n",
    "                                          'help': 'whether to use single layer or MLP as final classifier'\n",
    "                                      })\n",
    "    mlp_act: str = field(default='relu',\n",
    "                        metadata={\n",
    "                            'help': 'the activation function to use for finetuning layers',\n",
    "                            'choices': ['relu', 'prelu', 'sigmoid', 'tanh', 'linear']\n",
    "                        })\n",
    "    gating_beta: float = field(default=0.2,\n",
    "                              metadata={\n",
    "                                  'help': \"the beta hyperparameters used for gating tabular data \"\n",
    "                                          \"see https://www.aclweb.org/anthology/2020.acl-main.214.pdf\"\n",
    "                              })\n",
    "\n",
    "    def __post_init__(self):\n",
    "        assert self.column_info != self.column_info_path\n",
    "        if self.column_info is None and self.column_info_path:\n",
    "            with open(self.column_info_path, 'r') as f:\n",
    "                self.column_info = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "proper-curve",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_cols = ['text']\n",
    "cat_cols = ['question_mark', 'contains_url', 'contains_media', 'contains_profile_background_image', 'verified', 'geo_enabled', 'has_description']\n",
    "numerical_cols = ['retweet_count', 'favorite_count', 'number_urls','statuses_count', 'listed_count', 'reputation_score_1', 'reputation_score_2', 'favourites_count','length_description','follow_tweets']\n",
    "\n",
    "column_info_dict = {\n",
    "    'text_cols': text_cols,\n",
    "    'num_cols': numerical_cols,\n",
    "    'cat_cols': cat_cols,\n",
    "    'label_col': 'label',\n",
    "    'label_list': [0, 1]\n",
    "}\n",
    "\n",
    "\n",
    "model_args = ModelArguments(\n",
    "    model_name_or_path='bert-base-uncased'\n",
    ")\n",
    "\n",
    "data_args = MultimodalDataTrainingArguments(\n",
    "    data_path='.',\n",
    "    combine_feat_method='gating_on_cat_and_num_feats_then_sum',\n",
    "    column_info=column_info_dict,\n",
    "    task='classification'\n",
    ")\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./logs/model_name\",\n",
    "    logging_dir=\"./logs/runs\",\n",
    "    overwrite_output_dir=True,\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    per_device_train_batch_size=4,\n",
    "    num_train_epochs=5,\n",
    "    evaluate_during_training=True,\n",
    "    logging_steps=25,\n",
    "    eval_steps=250,\n",
    "    dataloader_drop_last=True\n",
    ")\n",
    "\n",
    "set_seed(training_args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "mediterranean-inside",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specified tokenizer:  bert-base-uncased\n"
     ]
    }
   ],
   "source": [
    "tokenizer_path_or_name = model_args.tokenizer_name if model_args.tokenizer_name else model_args.model_name_or_path\n",
    "print('Specified tokenizer: ', tokenizer_path_or_name)\n",
    "\n",
    "# Tokens automatically converted to lower_case\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    tokenizer_path_or_name,\n",
    "    cache_dir=model_args.cache_dir\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "polar-camping",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:multimodal_transformers.data.data_utils:9 numerical columns\n",
      "/opt/conda/lib/python3.7/site-packages/pandas/core/frame.py:3191: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[k1] = value[k2]\n",
      "INFO:multimodal_transformers.data.data_utils:20 categorical columns\n",
      "INFO:multimodal_transformers.data.data_utils:9 numerical columns\n",
      "/opt/conda/lib/python3.7/site-packages/pandas/core/frame.py:3191: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[k1] = value[k2]\n",
      "INFO:multimodal_transformers.data.load_data:Text columns: ['text']\n",
      "INFO:multimodal_transformers.data.load_data:Raw text example: respond murderous attack charlie hebdo newspaper free world print [SEP] jews label like anti semite campaign person company finish [SEP]  [SEP] imcharliehebdo [SEP] ditto [SEP] innocent muslim ought find insulting atrocity commit sodding cartoon [SEP] yes [SEP] insult people people genuinely offend drawing [SEP] think little actual muslim [SEP] like jew bye bye [SEP] kid benign stuff      wham like river shite [SEP] good point [SEP]  [SEP] organise jewry mean actual people hate ancestor [SEP]  [SEP] explore [SEP] case problem [SEP] point insult billion innocent muslim thumb nose bunch lunatic worth [SEP] dear     see tweet     block [SEP] learn offend [SEP] token jew black irish people learn offend [SEP] defend right free speech broad context [SEP] record way shape form defend atrocity [SEP] yes remind time jew bomb guardian [SEP] know give creep [SEP] lot dodgy twitter account benign real [SEP] people insult important feel identity attack [SEP] remarkable quickly come woodwork [SEP] correct response brutality offend lot people support brutality [SEP] \n",
      "INFO:multimodal_transformers.data.data_utils:20 categorical columns\n",
      "INFO:multimodal_transformers.data.data_utils:9 numerical columns\n",
      "/opt/conda/lib/python3.7/site-packages/pandas/core/frame.py:3191: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[k1] = value[k2]\n",
      "INFO:multimodal_transformers.data.load_data:Text columns: ['text']\n",
      "INFO:multimodal_transformers.data.load_data:Raw text example: people able sydney cafe hostage situation [SEP] fucking terrorist [SEP]  [SEP]  [SEP] people able sydney cafe hostage situation [SEP] finger look break [SEP] otage libre people able sydney cafe [SEP] definitely add tweet [SEP] people able sydney cafe hostage situation      cuba usa [SEP] stop show face go trouble forever link event [SEP] sure hope hostage taker get foot room temp [SEP] people able sydney cafe hostage situation [SEP] dear swat team guy want choose long rifle precise shot csi miami vice [SEP] radical islam spread terror [SEP]  [SEP] muslim fanatical zealot isis syndeysiege [SEP] connection long free democratic nation go allow terrorist state sponsor terror dictate [SEP] \n",
      "INFO:multimodal_transformers.data.data_utils:20 categorical columns\n",
      "INFO:multimodal_transformers.data.data_utils:9 numerical columns\n",
      "/opt/conda/lib/python3.7/site-packages/pandas/core/frame.py:3191: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[k1] = value[k2]\n",
      "INFO:multimodal_transformers.data.load_data:Text columns: ['text']\n",
      "INFO:multimodal_transformers.data.load_data:Raw text example: break report     brother suspect charlie hebdo attack dead [SEP] unfortunate get want die martyr glad french people [SEP] suck think big picture need know know work [SEP] break report     brother suspect charlie hebdo attack dead go hell [SEP] get kill one order kill journalist right guess [SEP]  [SEP] break report     brother suspect charlie hebdo attack dead jesuischarlie [SEP] break report     brother suspect charlie hebdo attack dead good [SEP] break report     brother suspect charlie hebdo attack dead [SEP] break report     brother suspect charlie hebdo attack dead [SEP] give hear favorite radio station area thank write [SEP] \n"
     ]
    }
   ],
   "source": [
    "# Get Datasets\n",
    "train_dataset, dev_dataset, test_dataset = load_data_from_folder(train_df, dev_df, test_df,\n",
    "    data_args.column_info['text_cols'],\n",
    "    tokenizer,\n",
    "    label_col=data_args.column_info['label_col'],\n",
    "    label_list=data_args.column_info['label_list'],\n",
    "    categorical_cols=data_args.column_info['cat_cols'],\n",
    "    numerical_cols=data_args.column_info['num_cols'],\n",
    "    sep_text_token_str=tokenizer.sep_token\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "enabling-rough",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<multimodal_transformers.data.tabular_torch_dataset.TorchTabularTextDataset at 0x7f3cea7db3d0>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "annual-bowling",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_labels = len(np.unique(train_dataset.labels))\n",
    "num_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "prepared-entrance",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = AutoConfig.from_pretrained(\n",
    "        model_args.config_name if model_args.config_name else model_args.model_name_or_path,\n",
    "        cache_dir=model_args.cache_dir,\n",
    "    )\n",
    "tabular_config = TabularConfig(num_labels=num_labels,\n",
    "                               cat_feat_dim=train_dataset.cat_feats.shape[1],\n",
    "                               numerical_feat_dim=train_dataset.numerical_feats.shape[1],\n",
    "                               **vars(data_args))\n",
    "config.tabular_config = tabular_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "published-stanford",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertWithTabular: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertWithTabular from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BertWithTabular from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertWithTabular were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias', 'tabular_combiner.h_bias', 'tabular_combiner.num_bn.weight', 'tabular_combiner.num_bn.bias', 'tabular_combiner.num_bn.running_mean', 'tabular_combiner.num_bn.running_var', 'tabular_combiner.g_cat_layer.weight', 'tabular_combiner.g_cat_layer.bias', 'tabular_combiner.h_cat_layer.weight', 'tabular_combiner.g_num_layer.weight', 'tabular_combiner.g_num_layer.bias', 'tabular_combiner.h_num_layer.weight', 'tabular_combiner.layer_norm.weight', 'tabular_combiner.layer_norm.bias', 'tabular_classifier.weight', 'tabular_classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelWithTabular.from_pretrained(\n",
    "        model_args.config_name if model_args.config_name else model_args.model_name_or_path,\n",
    "        config=config,\n",
    "        cache_dir=model_args.cache_dir\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "deadly-connectivity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport numpy as np\\nfrom scipy.special import softmax\\nfrom sklearn.metrics import (\\n    auc,\\n    precision_recall_curve,\\n    roc_auc_score,\\n    f1_score,\\n    confusion_matrix,\\n    matthews_corrcoef,\\n)\\n\\ndef calc_classification_metrics(p: EvalPrediction):\\n    pred_labels = np.argmax(p.predictions, axis=1)\\n    pred_scores = softmax(p.predictions, axis=1)[:, 1]\\n    labels = p.label_ids\\n    if len(np.unique(labels)) == 2:  # binary classification\\n        roc_auc_pred_score = roc_auc_score(labels, pred_scores)\\n        precisions, recalls, thresholds = precision_recall_curve(labels,\\n                                                                pred_scores)\\n        fscore = (2 * precisions * recalls) / (precisions + recalls)\\n        fscore[np.isnan(fscore)] = 0\\n        ix = np.argmax(fscore)\\n        threshold = thresholds[ix].item()\\n        pr_auc = auc(recalls, precisions)\\n        tn, fp, fn, tp = confusion_matrix(labels, pred_labels, labels=[0, 1]).ravel()\\n        result = {\\'roc_auc\\': roc_auc_pred_score,\\n                \\'threshold\\': threshold,\\n                \\'pr_auc\\': pr_auc,\\n                \\'recall\\': recalls[ix].item(),\\n                \\'precision\\': precisions[ix].item(), \\'f1\\': fscore[ix].item(),\\n                \\'tn\\': tn.item(), \\'fp\\': fp.item(), \\'fn\\': fn.item(), \\'tp\\': tp.item()\\n                }\\n    else:\\n        acc = (pred_labels == labels).mean()\\n        f1 = f1_score(y_true=labels, y_pred=pred_labels)\\n        result = {\\n          \"acc\": acc,\\n          \"f1\": f1,\\n          \"acc_and_f1\": (acc + f1) / 2,\\n          \"mcc\": matthews_corrcoef(labels, pred_labels)\\n        }\\n\\n    return result\\n'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "from sklearn.metrics import (\n",
    "    auc,\n",
    "    precision_recall_curve,\n",
    "    roc_auc_score,\n",
    "    f1_score,\n",
    "    confusion_matrix,\n",
    "    matthews_corrcoef,\n",
    ")\n",
    "\n",
    "def calc_classification_metrics(p: EvalPrediction):\n",
    "    pred_labels = np.argmax(p.predictions, axis=1)\n",
    "    pred_scores = softmax(p.predictions, axis=1)[:, 1]\n",
    "    labels = p.label_ids\n",
    "    if len(np.unique(labels)) == 2:  # binary classification\n",
    "        roc_auc_pred_score = roc_auc_score(labels, pred_scores)\n",
    "        precisions, recalls, thresholds = precision_recall_curve(labels,\n",
    "                                                                pred_scores)\n",
    "        fscore = (2 * precisions * recalls) / (precisions + recalls)\n",
    "        fscore[np.isnan(fscore)] = 0\n",
    "        ix = np.argmax(fscore)\n",
    "        threshold = thresholds[ix].item()\n",
    "        pr_auc = auc(recalls, precisions)\n",
    "        tn, fp, fn, tp = confusion_matrix(labels, pred_labels, labels=[0, 1]).ravel()\n",
    "        result = {'roc_auc': roc_auc_pred_score,\n",
    "                'threshold': threshold,\n",
    "                'pr_auc': pr_auc,\n",
    "                'recall': recalls[ix].item(),\n",
    "                'precision': precisions[ix].item(), 'f1': fscore[ix].item(),\n",
    "                'tn': tn.item(), 'fp': fp.item(), 'fn': fn.item(), 'tp': tp.item()\n",
    "                }\n",
    "    else:\n",
    "        acc = (pred_labels == labels).mean()\n",
    "        f1 = f1_score(y_true=labels, y_pred=pred_labels)\n",
    "        result = {\n",
    "          \"acc\": acc,\n",
    "          \"f1\": f1,\n",
    "          \"acc_and_f1\": (acc + f1) / 2,\n",
    "          \"mcc\": matthews_corrcoef(labels, pred_labels)\n",
    "        }\n",
    "\n",
    "    return result\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "spiritual-swing",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import torch\n",
    "#torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "expanded-wedding",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=dev_dataset\n",
    ")\n",
    "# compute_metrics=calc_classification_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "theoretical-performance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75951cdd261d4b51bcc95abcadf7e5e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a80f7358b4334791b3c76a350bddc9ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/1160 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7320793151855469, 'learning_rate': 4.978448275862069e-05, 'epoch': 0.021551724137931036, 'step': 25}\n",
      "{'loss': 0.5969670104980469, 'learning_rate': 4.9568965517241384e-05, 'epoch': 0.04310344827586207, 'step': 50}\n",
      "{'loss': 0.6636334228515625, 'learning_rate': 4.935344827586207e-05, 'epoch': 0.06465517241379311, 'step': 75}\n",
      "{'loss': 0.5826614379882813, 'learning_rate': 4.913793103448276e-05, 'epoch': 0.08620689655172414, 'step': 100}\n",
      "{'loss': 0.6537063598632813, 'learning_rate': 4.892241379310345e-05, 'epoch': 0.10775862068965517, 'step': 125}\n",
      "{'loss': 0.6578781127929687, 'learning_rate': 4.870689655172414e-05, 'epoch': 0.12931034482758622, 'step': 150}\n",
      "{'loss': 0.6459063720703125, 'learning_rate': 4.849137931034483e-05, 'epoch': 0.15086206896551724, 'step': 175}\n",
      "{'loss': 0.5088858032226562, 'learning_rate': 4.827586206896552e-05, 'epoch': 0.1724137931034483, 'step': 200}\n",
      "{'loss': 0.6277755737304688, 'learning_rate': 4.806034482758621e-05, 'epoch': 0.1939655172413793, 'step': 225}\n",
      "{'loss': 0.6091265869140625, 'learning_rate': 4.78448275862069e-05, 'epoch': 0.21551724137931033, 'step': 250}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5535052727c4d54a5ef4cb5e3845520",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation:   0%|          | 0/72 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5281306765973568, 'epoch': 0.21551724137931033, 'step': 250}\n",
      "{'loss': 0.597335205078125, 'learning_rate': 4.762931034482759e-05, 'epoch': 0.23706896551724138, 'step': 275}\n",
      "{'loss': 0.4887872314453125, 'learning_rate': 4.741379310344828e-05, 'epoch': 0.25862068965517243, 'step': 300}\n",
      "{'loss': 0.59904296875, 'learning_rate': 4.719827586206897e-05, 'epoch': 0.2801724137931034, 'step': 325}\n",
      "{'loss': 0.4641412353515625, 'learning_rate': 4.698275862068966e-05, 'epoch': 0.3017241379310345, 'step': 350}\n",
      "{'loss': 0.6923199462890625, 'learning_rate': 4.6767241379310346e-05, 'epoch': 0.3232758620689655, 'step': 375}\n",
      "{'loss': 0.578714599609375, 'learning_rate': 4.655172413793104e-05, 'epoch': 0.3448275862068966, 'step': 400}\n",
      "{'loss': 0.576748046875, 'learning_rate': 4.633620689655173e-05, 'epoch': 0.36637931034482757, 'step': 425}\n",
      "{'loss': 0.649656982421875, 'learning_rate': 4.612068965517242e-05, 'epoch': 0.3879310344827586, 'step': 450}\n",
      "{'loss': 0.518597412109375, 'learning_rate': 4.590517241379311e-05, 'epoch': 0.40948275862068967, 'step': 475}\n",
      "{'loss': 0.506732177734375, 'learning_rate': 4.5689655172413794e-05, 'epoch': 0.43103448275862066, 'step': 500}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b3f7deeb557493d94c41426ab402df5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation:   0%|          | 0/72 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5121819867442051, 'epoch': 0.43103448275862066, 'step': 500}\n",
      "{'loss': 0.58185302734375, 'learning_rate': 4.5474137931034485e-05, 'epoch': 0.4525862068965517, 'step': 525}\n",
      "{'loss': 0.4774560546875, 'learning_rate': 4.5258620689655176e-05, 'epoch': 0.47413793103448276, 'step': 550}\n",
      "{'loss': 0.564193115234375, 'learning_rate': 4.504310344827587e-05, 'epoch': 0.4956896551724138, 'step': 575}\n",
      "{'loss': 0.62172119140625, 'learning_rate': 4.482758620689655e-05, 'epoch': 0.5172413793103449, 'step': 600}\n",
      "{'loss': 0.639105224609375, 'learning_rate': 4.461206896551724e-05, 'epoch': 0.5387931034482759, 'step': 625}\n",
      "{'loss': 0.565242919921875, 'learning_rate': 4.4396551724137933e-05, 'epoch': 0.5603448275862069, 'step': 650}\n",
      "{'loss': 0.52958984375, 'learning_rate': 4.418103448275862e-05, 'epoch': 0.5818965517241379, 'step': 675}\n",
      "{'loss': 0.59009033203125, 'learning_rate': 4.396551724137931e-05, 'epoch': 0.603448275862069, 'step': 700}\n",
      "{'loss': 0.571090087890625, 'learning_rate': 4.375e-05, 'epoch': 0.625, 'step': 725}\n",
      "{'loss': 0.56281982421875, 'learning_rate': 4.353448275862069e-05, 'epoch': 0.646551724137931, 'step': 750}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eebd78206c0344eca7450e6475fbc58d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation:   0%|          | 0/72 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5075280379710926, 'epoch': 0.646551724137931, 'step': 750}\n",
      "{'loss': 0.6191552734375, 'learning_rate': 4.331896551724138e-05, 'epoch': 0.6681034482758621, 'step': 775}\n",
      "{'loss': 0.645965576171875, 'learning_rate': 4.3103448275862066e-05, 'epoch': 0.6896551724137931, 'step': 800}\n",
      "{'loss': 0.52297607421875, 'learning_rate': 4.288793103448276e-05, 'epoch': 0.7112068965517241, 'step': 825}\n",
      "{'loss': 0.60324951171875, 'learning_rate': 4.267241379310345e-05, 'epoch': 0.7327586206896551, 'step': 850}\n",
      "{'loss': 0.535001220703125, 'learning_rate': 4.245689655172414e-05, 'epoch': 0.7543103448275862, 'step': 875}\n",
      "{'loss': 0.5755078125, 'learning_rate': 4.224137931034483e-05, 'epoch': 0.7758620689655172, 'step': 900}\n",
      "{'loss': 0.539013671875, 'learning_rate': 4.202586206896552e-05, 'epoch': 0.7974137931034483, 'step': 925}\n",
      "{'loss': 0.64329345703125, 'learning_rate': 4.1810344827586205e-05, 'epoch': 0.8189655172413793, 'step': 950}\n",
      "{'loss': 0.57313720703125, 'learning_rate': 4.1594827586206896e-05, 'epoch': 0.8405172413793104, 'step': 975}\n",
      "{'loss': 0.63346435546875, 'learning_rate': 4.1379310344827587e-05, 'epoch': 0.8620689655172413, 'step': 1000}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18088899e29a483683af0c93db337902",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation:   0%|          | 0/72 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.48247574600908494, 'epoch': 0.8620689655172413, 'step': 1000}\n",
      "{'loss': 0.56531005859375, 'learning_rate': 4.116379310344828e-05, 'epoch': 0.8836206896551724, 'step': 1025}\n",
      "{'loss': 0.51462890625, 'learning_rate': 4.094827586206897e-05, 'epoch': 0.9051724137931034, 'step': 1050}\n",
      "{'loss': 0.56205322265625, 'learning_rate': 4.073275862068966e-05, 'epoch': 0.9267241379310345, 'step': 1075}\n",
      "{'loss': 0.5455615234375, 'learning_rate': 4.0517241379310344e-05, 'epoch': 0.9482758620689655, 'step': 1100}\n",
      "{'loss': 0.4671484375, 'learning_rate': 4.0301724137931035e-05, 'epoch': 0.9698275862068966, 'step': 1125}\n",
      "{'loss': 0.51127197265625, 'learning_rate': 4.0086206896551726e-05, 'epoch': 0.9913793103448276, 'step': 1150}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b310eea16f847be9b6e4ac3121d5939",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/1160 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.58487548828125, 'learning_rate': 3.9870689655172416e-05, 'epoch': 1.0129310344827587, 'step': 1175}\n",
      "{'loss': 0.52560546875, 'learning_rate': 3.965517241379311e-05, 'epoch': 1.0344827586206897, 'step': 1200}\n",
      "{'loss': 0.29550048828125, 'learning_rate': 3.94396551724138e-05, 'epoch': 1.0560344827586208, 'step': 1225}\n",
      "{'loss': 0.7842626953125, 'learning_rate': 3.922413793103448e-05, 'epoch': 1.0775862068965518, 'step': 1250}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e0004d866d24d1aab5cb797a85d9305",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation:   0%|          | 0/72 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5576875511970785, 'epoch': 1.0775862068965518, 'step': 1250}\n",
      "{'loss': 0.62856201171875, 'learning_rate': 3.9008620689655174e-05, 'epoch': 1.0991379310344827, 'step': 1275}\n",
      "{'loss': 0.5961572265625, 'learning_rate': 3.8793103448275865e-05, 'epoch': 1.1206896551724137, 'step': 1300}\n",
      "{'loss': 0.59150146484375, 'learning_rate': 3.8577586206896555e-05, 'epoch': 1.1422413793103448, 'step': 1325}\n",
      "{'loss': 0.610654296875, 'learning_rate': 3.8362068965517246e-05, 'epoch': 1.1637931034482758, 'step': 1350}\n",
      "{'loss': 0.51314697265625, 'learning_rate': 3.814655172413794e-05, 'epoch': 1.1853448275862069, 'step': 1375}\n",
      "{'loss': 0.626650390625, 'learning_rate': 3.793103448275862e-05, 'epoch': 1.206896551724138, 'step': 1400}\n",
      "{'loss': 0.539677734375, 'learning_rate': 3.771551724137931e-05, 'epoch': 1.228448275862069, 'step': 1425}\n",
      "{'loss': 0.61462158203125, 'learning_rate': 3.7500000000000003e-05, 'epoch': 1.25, 'step': 1450}\n",
      "{'loss': 0.5386083984375, 'learning_rate': 3.7284482758620694e-05, 'epoch': 1.271551724137931, 'step': 1475}\n",
      "{'loss': 0.55642578125, 'learning_rate': 3.7068965517241385e-05, 'epoch': 1.293103448275862, 'step': 1500}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "625ffa29e30141a2863f403793214f26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation:   0%|          | 0/72 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5239744612740146, 'epoch': 1.293103448275862, 'step': 1500}\n",
      "{'loss': 0.68726318359375, 'learning_rate': 3.685344827586207e-05, 'epoch': 1.3146551724137931, 'step': 1525}\n",
      "{'loss': 0.6437158203125, 'learning_rate': 3.663793103448276e-05, 'epoch': 1.3362068965517242, 'step': 1550}\n",
      "{'loss': 0.5522216796875, 'learning_rate': 3.642241379310345e-05, 'epoch': 1.3577586206896552, 'step': 1575}\n",
      "{'loss': 0.66591552734375, 'learning_rate': 3.620689655172414e-05, 'epoch': 1.3793103448275863, 'step': 1600}\n",
      "{'loss': 0.657119140625, 'learning_rate': 3.5991379310344833e-05, 'epoch': 1.4008620689655173, 'step': 1625}\n",
      "{'loss': 0.63150634765625, 'learning_rate': 3.5775862068965524e-05, 'epoch': 1.4224137931034484, 'step': 1650}\n",
      "{'loss': 0.579462890625, 'learning_rate': 3.556034482758621e-05, 'epoch': 1.4439655172413794, 'step': 1675}\n",
      "{'loss': 0.5960107421875, 'learning_rate': 3.53448275862069e-05, 'epoch': 1.4655172413793103, 'step': 1700}\n",
      "{'loss': 0.4897314453125, 'learning_rate': 3.512931034482759e-05, 'epoch': 1.4870689655172413, 'step': 1725}\n",
      "{'loss': 0.58220703125, 'learning_rate': 3.4913793103448275e-05, 'epoch': 1.5086206896551724, 'step': 1750}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9e10629285e47d48b2b52c94915c1e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation:   0%|          | 0/72 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5312832509064012, 'epoch': 1.5086206896551724, 'step': 1750}\n",
      "{'loss': 0.71786865234375, 'learning_rate': 3.4698275862068966e-05, 'epoch': 1.5301724137931034, 'step': 1775}\n",
      "{'loss': 0.581982421875, 'learning_rate': 3.4482758620689657e-05, 'epoch': 1.5517241379310345, 'step': 1800}\n",
      "{'loss': 0.564033203125, 'learning_rate': 3.426724137931035e-05, 'epoch': 1.5732758620689655, 'step': 1825}\n",
      "{'loss': 0.544189453125, 'learning_rate': 3.405172413793103e-05, 'epoch': 1.5948275862068966, 'step': 1850}\n",
      "{'loss': 0.60484375, 'learning_rate': 3.383620689655172e-05, 'epoch': 1.6163793103448276, 'step': 1875}\n",
      "{'loss': 0.6485302734375, 'learning_rate': 3.3620689655172414e-05, 'epoch': 1.6379310344827587, 'step': 1900}\n",
      "{'loss': 0.5492724609375, 'learning_rate': 3.3405172413793105e-05, 'epoch': 1.6594827586206895, 'step': 1925}\n",
      "{'loss': 0.5917431640625, 'learning_rate': 3.3189655172413796e-05, 'epoch': 1.6810344827586206, 'step': 1950}\n",
      "{'loss': 0.5191796875, 'learning_rate': 3.297413793103448e-05, 'epoch': 1.7025862068965516, 'step': 1975}\n",
      "{'loss': 0.6544921875, 'learning_rate': 3.275862068965517e-05, 'epoch': 1.7241379310344827, 'step': 2000}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ea54a7f4a1444b18e24ff59986a1de5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation:   0%|          | 0/72 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5020458876258798, 'epoch': 1.7241379310344827, 'step': 2000}\n",
      "{'loss': 0.6525146484375, 'learning_rate': 3.254310344827586e-05, 'epoch': 1.7456896551724137, 'step': 2025}\n",
      "{'loss': 0.556259765625, 'learning_rate': 3.232758620689655e-05, 'epoch': 1.7672413793103448, 'step': 2050}\n",
      "{'loss': 0.565078125, 'learning_rate': 3.2112068965517244e-05, 'epoch': 1.7887931034482758, 'step': 2075}\n",
      "{'loss': 0.4760791015625, 'learning_rate': 3.1896551724137935e-05, 'epoch': 1.8103448275862069, 'step': 2100}\n",
      "{'loss': 0.5473779296875, 'learning_rate': 3.168103448275862e-05, 'epoch': 1.831896551724138, 'step': 2125}\n",
      "{'loss': 0.50130859375, 'learning_rate': 3.146551724137931e-05, 'epoch': 1.853448275862069, 'step': 2150}\n",
      "{'loss': 0.61603515625, 'learning_rate': 3.125e-05, 'epoch': 1.875, 'step': 2175}\n",
      "{'loss': 0.496689453125, 'learning_rate': 3.103448275862069e-05, 'epoch': 1.896551724137931, 'step': 2200}\n",
      "{'loss': 0.5495654296875, 'learning_rate': 3.081896551724138e-05, 'epoch': 1.918103448275862, 'step': 2225}\n",
      "{'loss': 0.558984375, 'learning_rate': 3.060344827586207e-05, 'epoch': 1.9396551724137931, 'step': 2250}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3a7421a2d8746ffb8f754cd8a15003c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation:   0%|          | 0/72 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.47532775273753536, 'epoch': 1.9396551724137931, 'step': 2250}\n",
      "{'loss': 0.509580078125, 'learning_rate': 3.0387931034482758e-05, 'epoch': 1.9612068965517242, 'step': 2275}\n",
      "{'loss': 0.54958984375, 'learning_rate': 3.017241379310345e-05, 'epoch': 1.9827586206896552, 'step': 2300}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bce8fc11c2674e8c8ddd6b14172dc92f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/1160 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5353515625, 'learning_rate': 2.995689655172414e-05, 'epoch': 2.0043103448275863, 'step': 2325}\n",
      "{'loss': 0.4999853515625, 'learning_rate': 2.974137931034483e-05, 'epoch': 2.0258620689655173, 'step': 2350}\n",
      "{'loss': 0.4860400390625, 'learning_rate': 2.952586206896552e-05, 'epoch': 2.0474137931034484, 'step': 2375}\n",
      "{'loss': 0.456337890625, 'learning_rate': 2.9310344827586206e-05, 'epoch': 2.0689655172413794, 'step': 2400}\n",
      "{'loss': 0.6574365234375, 'learning_rate': 2.9094827586206897e-05, 'epoch': 2.0905172413793105, 'step': 2425}\n",
      "{'loss': 0.464921875, 'learning_rate': 2.8879310344827588e-05, 'epoch': 2.1120689655172415, 'step': 2450}\n",
      "{'loss': 0.501455078125, 'learning_rate': 2.866379310344828e-05, 'epoch': 2.1336206896551726, 'step': 2475}\n",
      "{'loss': 0.5910595703125, 'learning_rate': 2.844827586206897e-05, 'epoch': 2.1551724137931036, 'step': 2500}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e74cfc9d2a64543af19820ee90f9505",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation:   0%|          | 0/72 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.44759229612019324, 'epoch': 2.1551724137931036, 'step': 2500}\n",
      "{'loss': 0.491298828125, 'learning_rate': 2.8232758620689657e-05, 'epoch': 2.1767241379310347, 'step': 2525}\n",
      "{'loss': 0.5008251953125, 'learning_rate': 2.8017241379310345e-05, 'epoch': 2.1982758620689653, 'step': 2550}\n",
      "{'loss': 0.548173828125, 'learning_rate': 2.7801724137931036e-05, 'epoch': 2.2198275862068964, 'step': 2575}\n",
      "{'loss': 0.4869287109375, 'learning_rate': 2.7586206896551727e-05, 'epoch': 2.2413793103448274, 'step': 2600}\n",
      "{'loss': 0.360908203125, 'learning_rate': 2.7370689655172414e-05, 'epoch': 2.2629310344827585, 'step': 2625}\n",
      "{'loss': 0.6636328125, 'learning_rate': 2.7155172413793105e-05, 'epoch': 2.2844827586206895, 'step': 2650}\n",
      "{'loss': 0.4993798828125, 'learning_rate': 2.6939655172413796e-05, 'epoch': 2.3060344827586206, 'step': 2675}\n",
      "{'loss': 0.4690185546875, 'learning_rate': 2.672413793103448e-05, 'epoch': 2.3275862068965516, 'step': 2700}\n",
      "{'loss': 0.622451171875, 'learning_rate': 2.650862068965517e-05, 'epoch': 2.3491379310344827, 'step': 2725}\n",
      "{'loss': 0.58451171875, 'learning_rate': 2.6293103448275862e-05, 'epoch': 2.3706896551724137, 'step': 2750}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38aff886832d4458b52daf524704dcd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation:   0%|          | 0/72 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.45269018991125953, 'epoch': 2.3706896551724137, 'step': 2750}\n",
      "{'loss': 0.55255859375, 'learning_rate': 2.6077586206896553e-05, 'epoch': 2.3922413793103448, 'step': 2775}\n",
      "{'loss': 0.5743994140625, 'learning_rate': 2.5862068965517244e-05, 'epoch': 2.413793103448276, 'step': 2800}\n",
      "{'loss': 0.5100048828125, 'learning_rate': 2.5646551724137935e-05, 'epoch': 2.435344827586207, 'step': 2825}\n",
      "{'loss': 0.6708447265625, 'learning_rate': 2.543103448275862e-05, 'epoch': 2.456896551724138, 'step': 2850}\n",
      "{'loss': 0.5584814453125, 'learning_rate': 2.521551724137931e-05, 'epoch': 2.478448275862069, 'step': 2875}\n",
      "{'loss': 0.5103515625, 'learning_rate': 2.5e-05, 'epoch': 2.5, 'step': 2900}\n",
      "{'loss': 0.603173828125, 'learning_rate': 2.4784482758620692e-05, 'epoch': 2.521551724137931, 'step': 2925}\n",
      "{'loss': 0.608603515625, 'learning_rate': 2.456896551724138e-05, 'epoch': 2.543103448275862, 'step': 2950}\n",
      "{'loss': 0.6482666015625, 'learning_rate': 2.435344827586207e-05, 'epoch': 2.564655172413793, 'step': 2975}\n",
      "{'loss': 0.6881591796875, 'learning_rate': 2.413793103448276e-05, 'epoch': 2.586206896551724, 'step': 3000}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e6c7093d731401c902db3b348439f02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation:   0%|          | 0/72 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6472418492452966, 'epoch': 2.586206896551724, 'step': 3000}\n",
      "{'loss': 0.61701171875, 'learning_rate': 2.392241379310345e-05, 'epoch': 2.6077586206896552, 'step': 3025}\n",
      "{'loss': 0.551064453125, 'learning_rate': 2.370689655172414e-05, 'epoch': 2.6293103448275863, 'step': 3050}\n",
      "{'loss': 0.4997412109375, 'learning_rate': 2.349137931034483e-05, 'epoch': 2.6508620689655173, 'step': 3075}\n",
      "{'loss': 0.5933740234375, 'learning_rate': 2.327586206896552e-05, 'epoch': 2.6724137931034484, 'step': 3100}\n",
      "{'loss': 0.6162548828125, 'learning_rate': 2.306034482758621e-05, 'epoch': 2.6939655172413794, 'step': 3125}\n",
      "{'loss': 0.3707861328125, 'learning_rate': 2.2844827586206897e-05, 'epoch': 2.7155172413793105, 'step': 3150}\n",
      "{'loss': 0.518056640625, 'learning_rate': 2.2629310344827588e-05, 'epoch': 2.737068965517241, 'step': 3175}\n",
      "{'loss': 0.603583984375, 'learning_rate': 2.2413793103448276e-05, 'epoch': 2.7586206896551726, 'step': 3200}\n",
      "{'loss': 0.56357421875, 'learning_rate': 2.2198275862068967e-05, 'epoch': 2.780172413793103, 'step': 3225}\n",
      "{'loss': 0.5399365234375, 'learning_rate': 2.1982758620689654e-05, 'epoch': 2.8017241379310347, 'step': 3250}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea1744e707214153aabddc8599b8f667",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation:   0%|          | 0/72 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4793462680859698, 'epoch': 2.8017241379310347, 'step': 3250}\n",
      "{'loss': 0.6689453125, 'learning_rate': 2.1767241379310345e-05, 'epoch': 2.8232758620689653, 'step': 3275}\n",
      "{'loss': 0.5510302734375, 'learning_rate': 2.1551724137931033e-05, 'epoch': 2.844827586206897, 'step': 3300}\n",
      "{'loss': 0.52771484375, 'learning_rate': 2.1336206896551724e-05, 'epoch': 2.8663793103448274, 'step': 3325}\n",
      "{'loss': 0.68904296875, 'learning_rate': 2.1120689655172415e-05, 'epoch': 2.887931034482759, 'step': 3350}\n",
      "{'loss': 0.582275390625, 'learning_rate': 2.0905172413793102e-05, 'epoch': 2.9094827586206895, 'step': 3375}\n",
      "{'loss': 0.5940087890625, 'learning_rate': 2.0689655172413793e-05, 'epoch': 2.9310344827586206, 'step': 3400}\n",
      "{'loss': 0.484794921875, 'learning_rate': 2.0474137931034484e-05, 'epoch': 2.9525862068965516, 'step': 3425}\n",
      "{'loss': 0.459453125, 'learning_rate': 2.0258620689655172e-05, 'epoch': 2.9741379310344827, 'step': 3450}\n",
      "{'loss': 0.437265625, 'learning_rate': 2.0043103448275863e-05, 'epoch': 2.9956896551724137, 'step': 3475}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47973154908147f38f701518643f3ad8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/1160 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4273193359375, 'learning_rate': 1.9827586206896554e-05, 'epoch': 3.0172413793103448, 'step': 3500}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e725cc775a64c5ba9ad237137e4ca7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation:   0%|          | 0/72 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5591199244889948, 'epoch': 3.0172413793103448, 'step': 3500}\n",
      "{'loss': 0.5425927734375, 'learning_rate': 1.961206896551724e-05, 'epoch': 3.038793103448276, 'step': 3525}\n",
      "{'loss': 0.5, 'learning_rate': 1.9396551724137932e-05, 'epoch': 3.060344827586207, 'step': 3550}\n",
      "{'loss': 0.5054296875, 'learning_rate': 1.9181034482758623e-05, 'epoch': 3.081896551724138, 'step': 3575}\n",
      "{'loss': 0.5446826171875, 'learning_rate': 1.896551724137931e-05, 'epoch': 3.103448275862069, 'step': 3600}\n",
      "{'loss': 0.4680078125, 'learning_rate': 1.8750000000000002e-05, 'epoch': 3.125, 'step': 3625}\n",
      "{'loss': 0.5540234375, 'learning_rate': 1.8534482758620693e-05, 'epoch': 3.146551724137931, 'step': 3650}\n",
      "{'loss': 0.62345703125, 'learning_rate': 1.831896551724138e-05, 'epoch': 3.168103448275862, 'step': 3675}\n",
      "{'loss': 0.595458984375, 'learning_rate': 1.810344827586207e-05, 'epoch': 3.189655172413793, 'step': 3700}\n",
      "{'loss': 0.48359375, 'learning_rate': 1.7887931034482762e-05, 'epoch': 3.211206896551724, 'step': 3725}\n",
      "{'loss': 0.388515625, 'learning_rate': 1.767241379310345e-05, 'epoch': 3.2327586206896552, 'step': 3750}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f087a4d81fa34473b3c371303e51e3c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation:   0%|          | 0/72 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4815957127656374, 'epoch': 3.2327586206896552, 'step': 3750}\n",
      "{'loss': 0.55970703125, 'learning_rate': 1.7456896551724137e-05, 'epoch': 3.2543103448275863, 'step': 3775}\n",
      "{'loss': 0.7755859375, 'learning_rate': 1.7241379310344828e-05, 'epoch': 3.2758620689655173, 'step': 3800}\n",
      "{'loss': 0.503994140625, 'learning_rate': 1.7025862068965516e-05, 'epoch': 3.2974137931034484, 'step': 3825}\n",
      "{'loss': 0.50763671875, 'learning_rate': 1.6810344827586207e-05, 'epoch': 3.3189655172413794, 'step': 3850}\n",
      "{'loss': 0.576923828125, 'learning_rate': 1.6594827586206898e-05, 'epoch': 3.3405172413793105, 'step': 3875}\n",
      "{'loss': 0.470703125, 'learning_rate': 1.6379310344827585e-05, 'epoch': 3.3620689655172415, 'step': 3900}\n",
      "{'loss': 0.547939453125, 'learning_rate': 1.6163793103448276e-05, 'epoch': 3.3836206896551726, 'step': 3925}\n",
      "{'loss': 0.5341796875, 'learning_rate': 1.5948275862068967e-05, 'epoch': 3.405172413793103, 'step': 3950}\n",
      "{'loss': 0.512431640625, 'learning_rate': 1.5732758620689655e-05, 'epoch': 3.4267241379310347, 'step': 3975}\n",
      "{'loss': 0.415673828125, 'learning_rate': 1.5517241379310346e-05, 'epoch': 3.4482758620689653, 'step': 4000}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9bf2cd488f9493c86c8589f6c42a596",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation:   0%|          | 0/72 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.43435351628189284, 'epoch': 3.4482758620689653, 'step': 4000}\n",
      "{'loss': 0.466962890625, 'learning_rate': 1.5301724137931033e-05, 'epoch': 3.469827586206897, 'step': 4025}\n",
      "{'loss': 0.657919921875, 'learning_rate': 1.5086206896551724e-05, 'epoch': 3.4913793103448274, 'step': 4050}\n",
      "{'loss': 0.5426171875, 'learning_rate': 1.4870689655172415e-05, 'epoch': 3.512931034482759, 'step': 4075}\n",
      "{'loss': 0.479755859375, 'learning_rate': 1.4655172413793103e-05, 'epoch': 3.5344827586206895, 'step': 4100}\n",
      "{'loss': 0.452119140625, 'learning_rate': 1.4439655172413794e-05, 'epoch': 3.5560344827586206, 'step': 4125}\n",
      "{'loss': 0.63109375, 'learning_rate': 1.4224137931034485e-05, 'epoch': 3.5775862068965516, 'step': 4150}\n",
      "{'loss': 0.688544921875, 'learning_rate': 1.4008620689655172e-05, 'epoch': 3.5991379310344827, 'step': 4175}\n",
      "{'loss': 0.47623046875, 'learning_rate': 1.3793103448275863e-05, 'epoch': 3.6206896551724137, 'step': 4200}\n",
      "{'loss': 0.53892578125, 'learning_rate': 1.3577586206896553e-05, 'epoch': 3.6422413793103448, 'step': 4225}\n",
      "{'loss': 0.514521484375, 'learning_rate': 1.336206896551724e-05, 'epoch': 3.663793103448276, 'step': 4250}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36fd232a0e424b5d8c5488544c05cec7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation:   0%|          | 0/72 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4764930248363978, 'epoch': 3.663793103448276, 'step': 4250}\n",
      "{'loss': 0.428408203125, 'learning_rate': 1.3146551724137931e-05, 'epoch': 3.685344827586207, 'step': 4275}\n",
      "{'loss': 0.634951171875, 'learning_rate': 1.2931034482758622e-05, 'epoch': 3.706896551724138, 'step': 4300}\n",
      "{'loss': 0.449638671875, 'learning_rate': 1.271551724137931e-05, 'epoch': 3.728448275862069, 'step': 4325}\n",
      "{'loss': 0.491064453125, 'learning_rate': 1.25e-05, 'epoch': 3.75, 'step': 4350}\n",
      "{'loss': 0.76146484375, 'learning_rate': 1.228448275862069e-05, 'epoch': 3.771551724137931, 'step': 4375}\n",
      "{'loss': 0.399755859375, 'learning_rate': 1.206896551724138e-05, 'epoch': 3.793103448275862, 'step': 4400}\n",
      "{'loss': 0.385244140625, 'learning_rate': 1.185344827586207e-05, 'epoch': 3.814655172413793, 'step': 4425}\n",
      "{'loss': 0.5253515625, 'learning_rate': 1.163793103448276e-05, 'epoch': 3.836206896551724, 'step': 4450}\n",
      "{'loss': 0.42771484375, 'learning_rate': 1.1422413793103449e-05, 'epoch': 3.8577586206896552, 'step': 4475}\n",
      "{'loss': 0.49275390625, 'learning_rate': 1.1206896551724138e-05, 'epoch': 3.8793103448275863, 'step': 4500}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5d83df6e9044bf5bfbaec71f1e2dd1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation:   0%|          | 0/72 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.43928039733630914, 'epoch': 3.8793103448275863, 'step': 4500}\n",
      "{'loss': 0.53544921875, 'learning_rate': 1.0991379310344827e-05, 'epoch': 3.9008620689655173, 'step': 4525}\n",
      "{'loss': 0.54662109375, 'learning_rate': 1.0775862068965516e-05, 'epoch': 3.9224137931034484, 'step': 4550}\n",
      "{'loss': 0.463017578125, 'learning_rate': 1.0560344827586207e-05, 'epoch': 3.9439655172413794, 'step': 4575}\n",
      "{'loss': 0.50830078125, 'learning_rate': 1.0344827586206897e-05, 'epoch': 3.9655172413793105, 'step': 4600}\n",
      "{'loss': 0.6694921875, 'learning_rate': 1.0129310344827586e-05, 'epoch': 3.987068965517241, 'step': 4625}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8b1b114ff5146a9ab4242281a7ea39d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/1160 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.583837890625, 'learning_rate': 9.913793103448277e-06, 'epoch': 4.008620689655173, 'step': 4650}\n",
      "{'loss': 0.4606640625, 'learning_rate': 9.698275862068966e-06, 'epoch': 4.030172413793103, 'step': 4675}\n",
      "{'loss': 0.46861328125, 'learning_rate': 9.482758620689655e-06, 'epoch': 4.051724137931035, 'step': 4700}\n",
      "{'loss': 0.638701171875, 'learning_rate': 9.267241379310346e-06, 'epoch': 4.073275862068965, 'step': 4725}\n",
      "{'loss': 0.7244140625, 'learning_rate': 9.051724137931036e-06, 'epoch': 4.094827586206897, 'step': 4750}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f5c5846b8974c59afd8b19ca541d60d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation:   0%|          | 0/72 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4364030525709192, 'epoch': 4.094827586206897, 'step': 4750}\n",
      "{'loss': 0.54802734375, 'learning_rate': 8.836206896551725e-06, 'epoch': 4.116379310344827, 'step': 4775}\n",
      "{'loss': 0.487646484375, 'learning_rate': 8.620689655172414e-06, 'epoch': 4.137931034482759, 'step': 4800}\n",
      "{'loss': 0.61646484375, 'learning_rate': 8.405172413793103e-06, 'epoch': 4.1594827586206895, 'step': 4825}\n",
      "{'loss': 0.59296875, 'learning_rate': 8.189655172413793e-06, 'epoch': 4.181034482758621, 'step': 4850}\n",
      "{'loss': 0.311748046875, 'learning_rate': 7.974137931034484e-06, 'epoch': 4.202586206896552, 'step': 4875}\n",
      "{'loss': 0.707646484375, 'learning_rate': 7.758620689655173e-06, 'epoch': 4.224137931034483, 'step': 4900}\n",
      "{'loss': 0.496865234375, 'learning_rate': 7.543103448275862e-06, 'epoch': 4.245689655172414, 'step': 4925}\n",
      "{'loss': 0.44736328125, 'learning_rate': 7.3275862068965514e-06, 'epoch': 4.267241379310345, 'step': 4950}\n",
      "{'loss': 0.505029296875, 'learning_rate': 7.112068965517242e-06, 'epoch': 4.288793103448276, 'step': 4975}\n",
      "{'loss': 0.544814453125, 'learning_rate': 6.896551724137932e-06, 'epoch': 4.310344827586207, 'step': 5000}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d72078b6f4994dd7b8a9ae8686f80bc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation:   0%|          | 0/72 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.49047320473214817, 'epoch': 4.310344827586207, 'step': 5000}\n",
      "{'loss': 0.863759765625, 'learning_rate': 6.68103448275862e-06, 'epoch': 4.331896551724138, 'step': 5025}\n",
      "{'loss': 0.640810546875, 'learning_rate': 6.465517241379311e-06, 'epoch': 4.353448275862069, 'step': 5050}\n",
      "{'loss': 0.305732421875, 'learning_rate': 6.25e-06, 'epoch': 4.375, 'step': 5075}\n",
      "{'loss': 0.478720703125, 'learning_rate': 6.03448275862069e-06, 'epoch': 4.396551724137931, 'step': 5100}\n",
      "{'loss': 0.488349609375, 'learning_rate': 5.81896551724138e-06, 'epoch': 4.418103448275862, 'step': 5125}\n",
      "{'loss': 0.508720703125, 'learning_rate': 5.603448275862069e-06, 'epoch': 4.439655172413793, 'step': 5150}\n",
      "{'loss': 0.63107421875, 'learning_rate': 5.387931034482758e-06, 'epoch': 4.461206896551724, 'step': 5175}\n",
      "{'loss': 0.70166015625, 'learning_rate': 5.172413793103448e-06, 'epoch': 4.482758620689655, 'step': 5200}\n",
      "{'loss': 0.29697265625, 'learning_rate': 4.9568965517241384e-06, 'epoch': 4.504310344827586, 'step': 5225}\n",
      "{'loss': 0.45716796875, 'learning_rate': 4.741379310344828e-06, 'epoch': 4.525862068965517, 'step': 5250}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c72b79d71f2f43bc9a4ac684a3946440",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation:   0%|          | 0/72 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.49690183389207554, 'epoch': 4.525862068965517, 'step': 5250}\n",
      "{'loss': 0.583798828125, 'learning_rate': 4.525862068965518e-06, 'epoch': 4.547413793103448, 'step': 5275}\n",
      "{'loss': 0.61646484375, 'learning_rate': 4.310344827586207e-06, 'epoch': 4.568965517241379, 'step': 5300}\n",
      "{'loss': 0.4957421875, 'learning_rate': 4.094827586206896e-06, 'epoch': 4.5905172413793105, 'step': 5325}\n",
      "{'loss': 0.41404296875, 'learning_rate': 3.8793103448275865e-06, 'epoch': 4.612068965517241, 'step': 5350}\n",
      "{'loss': 0.525673828125, 'learning_rate': 3.6637931034482757e-06, 'epoch': 4.633620689655173, 'step': 5375}\n",
      "{'loss': 0.661904296875, 'learning_rate': 3.448275862068966e-06, 'epoch': 4.655172413793103, 'step': 5400}\n",
      "{'loss': 0.564541015625, 'learning_rate': 3.2327586206896555e-06, 'epoch': 4.676724137931035, 'step': 5425}\n",
      "{'loss': 0.3682421875, 'learning_rate': 3.017241379310345e-06, 'epoch': 4.698275862068965, 'step': 5450}\n",
      "{'loss': 0.38345703125, 'learning_rate': 2.8017241379310345e-06, 'epoch': 4.719827586206897, 'step': 5475}\n",
      "{'loss': 0.466015625, 'learning_rate': 2.586206896551724e-06, 'epoch': 4.741379310344827, 'step': 5500}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbe4d27c499d49fe96417d8c4bc3e97d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation:   0%|          | 0/72 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5417056862627052, 'epoch': 4.741379310344827, 'step': 5500}\n",
      "{'loss': 0.583154296875, 'learning_rate': 2.370689655172414e-06, 'epoch': 4.762931034482759, 'step': 5525}\n",
      "{'loss': 0.601728515625, 'learning_rate': 2.1551724137931035e-06, 'epoch': 4.7844827586206895, 'step': 5550}\n",
      "{'loss': 0.626494140625, 'learning_rate': 1.9396551724137932e-06, 'epoch': 4.806034482758621, 'step': 5575}\n",
      "{'loss': 0.5257421875, 'learning_rate': 1.724137931034483e-06, 'epoch': 4.827586206896552, 'step': 5600}\n",
      "{'loss': 0.5566796875, 'learning_rate': 1.5086206896551726e-06, 'epoch': 4.849137931034483, 'step': 5625}\n",
      "{'loss': 0.55205078125, 'learning_rate': 1.293103448275862e-06, 'epoch': 4.870689655172414, 'step': 5650}\n",
      "{'loss': 0.70755859375, 'learning_rate': 1.0775862068965518e-06, 'epoch': 4.892241379310345, 'step': 5675}\n",
      "{'loss': 0.53328125, 'learning_rate': 8.620689655172415e-07, 'epoch': 4.913793103448276, 'step': 5700}\n",
      "{'loss': 0.609248046875, 'learning_rate': 6.46551724137931e-07, 'epoch': 4.935344827586206, 'step': 5725}\n",
      "{'loss': 0.315771484375, 'learning_rate': 4.3103448275862073e-07, 'epoch': 4.956896551724138, 'step': 5750}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a443052434d43c9b1a9084b9a398274",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation:   0%|          | 0/72 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5022836247614274, 'epoch': 4.956896551724138, 'step': 5750}\n",
      "{'loss': 0.537470703125, 'learning_rate': 2.1551724137931036e-07, 'epoch': 4.978448275862069, 'step': 5775}\n",
      "{'loss': 0.638212890625, 'learning_rate': 0.0, 'epoch': 5.0, 'step': 5800}\n",
      "CPU times: user 1h 11min 32s, sys: 23min 29s, total: 1h 35min 2s\n",
      "Wall time: 1h 35min\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=5800, training_loss=0.5549590433054957)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "refined-georgia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "lesbian-cylinder",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 4644), started 0:01:13 ago. (Use '!kill 4644' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-1c80317fa3b1799d\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-1c80317fa3b1799d\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir ./logs/runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "dominican-carpet",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "581"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "senior-stationery",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(\"./multimodal_bert/multimodal_bert_v8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "about-avenue",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "developing-midwest",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to reload trainer because drop_last = True was set during training.\n",
    "pred_trained = Trainer(\n",
    "    model=model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "defined-spiritual",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fd4abf1f8284421aa09c0c634dfa0fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction:   0%|          | 0/73 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = pred_trained.predict(test_dataset=test_dataset).predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "progressive-transaction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "581"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "improved-parker",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.73183644,  0.86781955],\n",
       "       [-1.7730815 ,  1.3484974 ],\n",
       "       [-1.2793902 ,  1.0951074 ],\n",
       "       ...,\n",
       "       [-1.7770942 ,  1.3777128 ],\n",
       "       [ 1.3113612 , -2.4507856 ],\n",
       "       [ 1.5208449 , -2.6579978 ]], dtype=float32)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "affecting-project",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import softmax\n",
    "\n",
    "pred_labels = np.argmax(result, axis=1)\n",
    "pred_scores = softmax(result, axis=1)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "aging-twins",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0,\n",
       "       1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0,\n",
       "       0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0,\n",
       "       0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0,\n",
       "       0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1,\n",
       "       1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0,\n",
       "       1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0,\n",
       "       1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0,\n",
       "       0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "       1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0,\n",
       "       1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0,\n",
       "       0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "       0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1,\n",
       "       0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0,\n",
       "       1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0,\n",
       "       1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0,\n",
       "       0, 1, 0, 1, 0, 0, 1, 0, 0])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "approved-contributor",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = [convert_prediction(pred) for pred in pred_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "studied-saver",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>544382249178001408</td>\n",
       "      <td>rumour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>525027317551079424</td>\n",
       "      <td>rumour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>544273220128739329</td>\n",
       "      <td>rumour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>499571799764770816</td>\n",
       "      <td>non-rumour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>552844104418091008</td>\n",
       "      <td>non-rumour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576</th>\n",
       "      <td>553581227165642752</td>\n",
       "      <td>non-rumour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577</th>\n",
       "      <td>552816302780579840</td>\n",
       "      <td>non-rumour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>580350000074457088</td>\n",
       "      <td>rumour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>498584409055174656</td>\n",
       "      <td>non-rumour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>524961070465945600</td>\n",
       "      <td>non-rumour</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>581 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id      target\n",
       "0    544382249178001408      rumour\n",
       "1    525027317551079424      rumour\n",
       "2    544273220128739329      rumour\n",
       "3    499571799764770816  non-rumour\n",
       "4    552844104418091008  non-rumour\n",
       "..                  ...         ...\n",
       "576  553581227165642752  non-rumour\n",
       "577  552816302780579840  non-rumour\n",
       "578  580350000074457088      rumour\n",
       "579  498584409055174656  non-rumour\n",
       "580  524961070465945600  non-rumour\n",
       "\n",
       "[581 rows x 2 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = pd.DataFrame({'id':test_df.id,'target':predicted_labels})\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "scheduled-holmes",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.Series(output.target.values,index=output.id).to_dict()\n",
    "with open('test-output.json', 'w') as f:\n",
    "    json.dump(submission, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "junior-playback",
   "metadata": {},
   "source": [
    "## Text-only BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "naked-favorite",
   "metadata": {},
   "source": [
    "## Loading BertTokenizer\n",
    "\n",
    "Load tokenizer based on wordpiece approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "stylish-hepatitis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Check whether transformerss is allowed\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-large-uncased', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "valid-youth",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greek-bottle",
   "metadata": {},
   "source": [
    "## BERT encoding\n",
    "\n",
    "Data is encoded according to BERT requirement.There is a very helpful function called encode_plus provided in the Tokenizer class. It can seamlessly perform the following operations:\n",
    "\n",
    "Tokenize the text\n",
    "Add special tokens - [CLS] and [SEP]\n",
    "\n",
    "Add special tokens - [CLS] and [SEP]\n",
    "\n",
    "create token IDs\n",
    "\n",
    "Pad the sentences to a common length\n",
    "\n",
    "Create attention masks for the above PAD tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "american-obligation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_encode(data,maximum_length) :\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "\n",
    "\n",
    "    for i in range(len(data.text)):\n",
    "        encoded = tokenizer.encode_plus(\n",
    "            data.text[i],\n",
    "            add_special_tokens=True,\n",
    "            max_length=maximum_length,\n",
    "            pad_to_max_length=True,\n",
    "            return_attention_mask=True,\n",
    "            truncation = True\n",
    "\n",
    "        )\n",
    "\n",
    "        input_ids.append(encoded['input_ids'])\n",
    "        attention_masks.append(encoded['attention_mask'])\n",
    "    return np.array(input_ids),np.array(attention_masks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "simple-major",
   "metadata": {},
   "source": [
    "Input are 2 Numpy array. Let me briefly go over them:\n",
    "\n",
    "1) input_ids : list of token ids to be fed to a model\n",
    "\n",
    "2) attention_masks: list of indices specifying which tokens should be attended to by the model.The input sequences are denoted by 1 and the padded ones by 0. These masks help to differentiate between the two.\n",
    "\n",
    "Note : Token Ids are not necessary as it is used Two Sentence Problem (To differentiate two sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "environmental-sector",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "combined_input_ids,combined_attention_masks = bert_encode(combined_df,512)\n",
    "test_input_ids,test_attention_masks = bert_encode(test_df,512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "distinct-picnic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  101,  2129,  2000, ...,     0,     0,     0],\n",
       "       [  101,  2017,  2064, ...,  7499,  1012,   102],\n",
       "       [  101,  4740,  2000, ...,     0,     0,     0],\n",
       "       ...,\n",
       "       [  101,  2057,  2288, ...,  3808,  2034,   102],\n",
       "       [  101,  2197,  2597, ...,  7471,  3177,   102],\n",
       "       [  101, 13970, 12269, ...,     0,     0,     0]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "collective-velvet",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5221"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(combined_input_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "champion-admission",
   "metadata": {},
   "source": [
    "## Creating Custom Model\n",
    "\n",
    "Base TFBert Model with Dense layer and sigmoid activation as head."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "filled-sensitivity",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "def create_model(bert_model):\n",
    "    input_ids = tf.keras.Input(shape=(512,),dtype='int32')\n",
    "    attention_masks = tf.keras.Input(shape=(512,),dtype='int32')\n",
    "\n",
    "    output = bert_model([input_ids,attention_masks])\n",
    "    output = output[1]\n",
    "    output = tf.keras.layers.Dense(32,activation='relu')(output)\n",
    "    output = tf.keras.layers.Dropout(0.2)(output)\n",
    "\n",
    "    output = tf.keras.layers.Dense(1,activation='sigmoid')(output)\n",
    "    model = tf.keras.models.Model(inputs = [input_ids,attention_masks],outputs = output)\n",
    "    model.compile(Adam(lr=6e-6), loss='binary_crossentropy', metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "solar-vinyl",
   "metadata": {},
   "source": [
    "## TFBertModel\n",
    "\n",
    "The bare Bert Model transformer outputing raw hidden-states without any specific head on top. https://huggingface.co/transformers/model_doc/bert.html#tfbertmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "homeless-foster",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "nonprofit-henry",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-uncased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the model checkpoint at bert-large-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "from transformers import TFBertModel\n",
    "\n",
    "bert_model = TFBertModel.from_pretrained('bert-large-uncased')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "organizational-korean",
   "metadata": {},
   "source": [
    "## Implementing custom model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "descending-channels",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_bert_model (TFBertModel)     ((None, 512, 1024),  335141888   input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 32)           32800       tf_bert_model[0][1]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_73 (Dropout)            (None, 32)           0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            33          dropout_73[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 335,174,721\n",
      "Trainable params: 335,174,721\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model(bert_model)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greater-seminar",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "Fit for **5 epochs**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ambient-resistance",
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elegant-posting",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      " 180/2349 [=>............................] - ETA: 56:27 - loss: 0.7065 - accuracy: 0.5806 - precision: 0.4071 - recall: 0.3538"
     ]
    }
   ],
   "source": [
    "history = model.fit([combined_input_ids,combined_attention_masks],combined_df.label,validation_split=0.1,callbacks=[callback], epochs=5,batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "widespread-withdrawal",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subject-momentum",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indonesian-thursday",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"./pure_bert/pure_bert_v10\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "banned-geometry",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "square-corruption",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.predict([test_input_ids,test_attention_masks])\n",
    "result = np.round(result).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subtle-diameter",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = [convert_prediction(pred) for pred in result]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "banned-champion",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame({'id':test_df.id,'target':predicted_labels})\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loaded-belfast",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.Series(output.target.values,index=output.id).to_dict()\n",
    "with open('test-output.json', 'w') as f:\n",
    "    json.dump(submission, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "economic-piece",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "global-reading",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "careful-nashville",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-3.m65",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-3:m65"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
